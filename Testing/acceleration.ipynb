{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import sys\n",
    "sys.path.append('/Users/ziniuwu/Desktop/research/BayesCard')\n",
    "from Pgmpy.factors import factor_product\n",
    "from Pgmpy.models import BayesianModel, JunctionTree\n",
    "from Pgmpy.inference.EliminationOrder import (\n",
    "    WeightedMinFill,\n",
    "    MinNeighbors,\n",
    "    MinFill,\n",
    "    MinWeight,\n",
    ")\n",
    "from Pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "from Models.pgmpy_BN import Pgmpy_BN\n",
    "from Testing.toy_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableElimination(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        model.check_model()\n",
    "\n",
    "        if isinstance(model, JunctionTree):\n",
    "            self.variables = set(chain(*model.nodes()))\n",
    "        else:\n",
    "            self.variables = model.nodes()\n",
    "\n",
    "        self.cardinality = {}\n",
    "        self.factors = defaultdict(list)\n",
    "\n",
    "        if isinstance(model, BayesianModel):\n",
    "            self.state_names_map = {}\n",
    "            for node in model.nodes():\n",
    "                cpd = model.get_cpds(node)\n",
    "                if isinstance(cpd, TabularCPD):\n",
    "                    self.cardinality[node] = cpd.variable_card\n",
    "                    cpd = cpd.to_factor()\n",
    "                for var in cpd.scope():\n",
    "                    self.factors[var].append(cpd)\n",
    "                self.state_names_map.update(cpd.no_to_name)\n",
    "\n",
    "        elif isinstance(model, JunctionTree):\n",
    "            self.cardinality = model.get_cardinality()\n",
    "\n",
    "            for factor in model.get_factors():\n",
    "                for var in factor.variables:\n",
    "                    self.factors[var].append(factor)\n",
    "    \n",
    "    def _get_working_factors(self, evidence):\n",
    "        \"\"\"\n",
    "        Uses the evidence given to the query methods to modify the factors before running\n",
    "        the variable elimination algorithm.\n",
    "        Parameters\n",
    "        ----------\n",
    "        evidence: dict\n",
    "            Dict of the form {variable: state}\n",
    "        Returns\n",
    "        -------\n",
    "        dict: Modified working factors.\n",
    "        \"\"\"\n",
    "\n",
    "        working_factors = {\n",
    "            node: {(factor, None) for factor in self.factors[node]}\n",
    "            for node in self.factors\n",
    "        }\n",
    "\n",
    "        # Dealing with evidence. Reducing factors over it before VE is run.\n",
    "        if evidence:\n",
    "            for evidence_var in evidence:\n",
    "                for factor, origin in working_factors[evidence_var]:\n",
    "                    factor_reduced = factor.reduce(\n",
    "                        [(evidence_var, evidence[evidence_var])], inplace=False\n",
    "                    )\n",
    "                    for var in factor_reduced.scope():\n",
    "                        working_factors[var].remove((factor, origin))\n",
    "                        working_factors[var].add((factor_reduced, evidence_var))\n",
    "                if type(evidence[evidence_var]) != list:\n",
    "                    del working_factors[evidence_var]\n",
    "        return working_factors\n",
    "    \n",
    "    def _get_elimination_order(\n",
    "        self, variables, evidence, elimination_order=\"minfill\", show_progress=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Deals with all elimination order parameters given to _variable_elimination method\n",
    "        and returns a list of variables that are to be eliminated\n",
    "        Parameters\n",
    "        ----------\n",
    "        elimination_order: str or list\n",
    "        Returns\n",
    "        -------\n",
    "        list: A list of variables names in the order they need to be eliminated.\n",
    "        \"\"\"\n",
    "        not_evidence_eliminate = []\n",
    "        if evidence is not None:\n",
    "            for key in evidence:\n",
    "                if type(evidence[key]) != list:\n",
    "                    not_evidence_eliminate.append(key)\n",
    "        to_eliminate = (\n",
    "            set(self.variables)\n",
    "            - set(variables)\n",
    "            - set(not_evidence_eliminate)\n",
    "        )\n",
    "\n",
    "        # Step 1: If elimination_order is a list, verify it's correct and return.\n",
    "        if hasattr(elimination_order, \"__iter__\") and (\n",
    "            not isinstance(elimination_order, str)\n",
    "        ):\n",
    "            if any(\n",
    "                var in elimination_order\n",
    "                for var in set(variables).union(\n",
    "                    set(evidence.keys() if evidence else [])\n",
    "                )\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Elimination order contains variables which are in\"\n",
    "                    \" variables or evidence args\"\n",
    "                )\n",
    "            else:\n",
    "                return elimination_order\n",
    "\n",
    "        # Step 2: If elimination order is None or a Markov model, return a random order.\n",
    "        elif (elimination_order is None) or (not isinstance(self.model, BayesianModel)):\n",
    "            return to_eliminate\n",
    "\n",
    "        # Step 3: If elimination order is a str, compute the order using the specified heuristic.\n",
    "        elif isinstance(elimination_order, str) and isinstance(\n",
    "            self.model, BayesianModel\n",
    "        ):\n",
    "            heuristic_dict = {\n",
    "                \"weightedminfill\": WeightedMinFill,\n",
    "                \"minneighbors\": MinNeighbors,\n",
    "                \"minweight\": MinWeight,\n",
    "                \"minfill\": MinFill,\n",
    "            }\n",
    "            elimination_order = heuristic_dict[elimination_order.lower()](\n",
    "                self.model\n",
    "            ).get_elimination_order(nodes=to_eliminate, show_progress=show_progress)\n",
    "            return elimination_order\n",
    "    \n",
    "    def _variable_elimination(\n",
    "        self,\n",
    "        variables,\n",
    "        operation,\n",
    "        evidence=None,\n",
    "        elimination_order=\"MinFill\",\n",
    "        joint=True,\n",
    "        show_progress=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of a generalized variable elimination.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        variables: list, array-like\n",
    "            variables that are not to be eliminated.\n",
    "\n",
    "        operation: str ('marginalize' | 'maximize')\n",
    "            The operation to do for eliminating the variable.\n",
    "\n",
    "        evidence: dict\n",
    "            a dict key, value pair as {var: state_of_var_observed}\n",
    "            None if no evidence\n",
    "\n",
    "        elimination_order: str or list (array-like)\n",
    "            If str: Heuristic to use to find the elimination order.\n",
    "            If array-like: The elimination order to use.\n",
    "            If None: A random elimination order is used.\n",
    "        \"\"\"\n",
    "        # Step 1: Deal with the input arguments.\n",
    "        if isinstance(variables, str):\n",
    "            raise TypeError(\"variables must be a list of strings\")\n",
    "        if isinstance(evidence, str):\n",
    "            raise TypeError(\"evidence must be a list of strings\")\n",
    "\n",
    "        # Dealing with the case when variables is not provided.\n",
    "        if not variables:\n",
    "            all_factors = []\n",
    "            for factor_li in self.factors.values():\n",
    "                all_factors.extend(factor_li)\n",
    "            if joint:\n",
    "                return factor_product(*set(all_factors))\n",
    "            else:\n",
    "                return set(all_factors)\n",
    "\n",
    "        # Step 2: Prepare data structures to run the algorithm.\n",
    "        eliminated_variables = set()\n",
    "        # Get working factors and elimination order\n",
    "        tic = time.time()\n",
    "        working_factors = self._get_working_factors(evidence)\n",
    "        toc = time.time()\n",
    "        #print(f\"getting working factors takes {toc-tic} secs\")\n",
    "        elimination_order = self._get_elimination_order(\n",
    "            variables, evidence, elimination_order, show_progress=show_progress\n",
    "        )\n",
    "        #print(f\"getting elimination orders takes {time.time()-toc} secs\")\n",
    "        # Step 3: Run variable elimination\n",
    "        if show_progress:\n",
    "            pbar = tqdm(elimination_order)\n",
    "        else:\n",
    "            pbar = elimination_order\n",
    "\n",
    "        for var in pbar:\n",
    "            tic = time.time()\n",
    "            #print(var)\n",
    "            if show_progress:\n",
    "                pbar.set_description(\"Eliminating: {var}\".format(var=var))\n",
    "            # Removing all the factors containing the variables which are\n",
    "            # eliminated (as all the factors should be considered only once)\n",
    "            factors = [\n",
    "                factor\n",
    "                for factor, _ in working_factors[var]\n",
    "                if not set(factor.variables).intersection(eliminated_variables)\n",
    "            ]\n",
    "            #print(factors)\n",
    "            phi = factor_product(*factors)\n",
    "            phi = getattr(phi, operation)([var], inplace=False)\n",
    "            del working_factors[var]\n",
    "            for variable in phi.variables:\n",
    "                working_factors[variable].add((phi, var))\n",
    "            eliminated_variables.add(var)\n",
    "            #print(f\"eliminating {var} takes {time.time()-tic} secs\")\n",
    "            \n",
    "        # Step 4: Prepare variables to be returned.\n",
    "        tic = time.time()\n",
    "        final_distribution = set()\n",
    "        for node in working_factors:\n",
    "            for factor, origin in working_factors[node]:\n",
    "                if not set(factor.variables).intersection(eliminated_variables):\n",
    "                    final_distribution.add((factor, origin))\n",
    "        final_distribution = [factor for factor, _ in final_distribution]\n",
    "        #print(final_distribution)\n",
    "        #print(f\"the rest takes {time.time()-tic} secs\")\n",
    "        if joint:\n",
    "            if isinstance(self.model, BayesianModel):\n",
    "                return factor_product(*final_distribution).normalize(inplace=False)\n",
    "            else:\n",
    "                return factor_product(*final_distribution)\n",
    "        else:\n",
    "            query_var_factor = {}\n",
    "            for query_var in variables:\n",
    "                phi = factor_product(*final_distribution)\n",
    "                query_var_factor[query_var] = phi.marginalize(\n",
    "                    list(set(variables) - set([query_var])), inplace=False\n",
    "                ).normalize(inplace=False)\n",
    "            #print(f\"the rest takes {time.time()-tic} secs\")\n",
    "            return query_var_factor\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        variables,\n",
    "        evidence=None,\n",
    "        elimination_order=\"MinFill\",\n",
    "        joint=True,\n",
    "        show_progress=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        variables: list\n",
    "            list of variables for which you want to compute the probability\n",
    "\n",
    "        evidence: dict\n",
    "            a dict key, value pair as {var: state_of_var_observed}\n",
    "            None if no evidence\n",
    "\n",
    "        elimination_order: list\n",
    "            order of variable eliminations (if nothing is provided) order is\n",
    "            computed automatically\n",
    "\n",
    "        joint: boolean (default: True)\n",
    "            If True, returns a Joint Distribution over `variables`.\n",
    "            If False, returns a dict of distributions over each of the `variables`.\n",
    "        \"\"\"\n",
    "        common_vars = set(evidence if evidence is not None else []).intersection(\n",
    "            set(variables)\n",
    "        )\n",
    "        if common_vars:\n",
    "            raise ValueError(\n",
    "                f\"Can't have the same variables in both `variables` and `evidence`. Found in both: {common_vars}\"\n",
    "            )\n",
    "\n",
    "        return self._variable_elimination(\n",
    "            variables=variables,\n",
    "            operation=\"marginalize\",\n",
    "            evidence=evidence,\n",
    "            elimination_order=elimination_order,\n",
    "            joint=joint,\n",
    "            show_progress=show_progress,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('check_points/Census_chow-liu.pkl', 'rb') as f:\n",
    "    BN = pickle.load(f)\n",
    "with open('check_points/Census_junction.pkl', 'rb') as f:\n",
    "    BN_J = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ve = VariableElimination(BN.model)\n",
    "BN.infer_machine = ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2592971324920654\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "q = ve.query([\"iAvail\"], {\"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0})\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "class exper:\n",
    "    def __init__(self):\n",
    "        self.trace = None\n",
    "        \n",
    "    @jit\n",
    "    def go_fast(self, a): # Function is compiled and runs in machine code\n",
    "        trace = None\n",
    "        for i in range(a.shape[0]):\n",
    "            if trace is None:\n",
    "                trace = 0.0\n",
    "            trace += np.tanh(a[i, i])\n",
    "        return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "e = exper()\n",
    "start = time.time()\n",
    "e.go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.time()\n",
    "e.go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exper:\n",
    "    def __init__(self):\n",
    "        self.trace = None\n",
    "        \n",
    "    def go_fast(self, a): # Function is compiled and runs in machine code\n",
    "        trace = None\n",
    "        for i in range(a.shape[0]):\n",
    "            if trace is None:\n",
    "                trace = 0.0\n",
    "            trace += np.tanh(a[i, i])\n",
    "        return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "e = exper()\n",
    "start = time.time()\n",
    "e.go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
