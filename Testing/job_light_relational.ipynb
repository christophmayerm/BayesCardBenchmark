{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('/home/ziniu.wzn/BayesCard')\n",
    "import pandas as pd\n",
    "import time\n",
    "import bz2\n",
    "import pickle\n",
    "import logging\n",
    "import ast\n",
    "\n",
    "from Models.pgmpy_BN import Pgmpy_BN\n",
    "from Evaluation.utils import parse_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Schemas.imdb.schema import gen_job_light_imdb_schema\n",
    "from DataPrepare.join_data_preparation import JoinDataPreparator\n",
    "schema = gen_job_light_imdb_schema('/home/ziniu.wzn/imdb-benchmark')\n",
    "from DataPrepare.join_data_preparation import JoinDataPreparator\n",
    "hdf_path = \"/home/ziniu.wzn/imdb-benchmark/gen_single_light\"\n",
    "meta_data_path = hdf_path + '/meta_data.pkl'\n",
    "prep = JoinDataPreparator(meta_data_path, schema, max_table_data=20000000)\n",
    "for relationship_obj in schema.relationships:\n",
    "    print(relationship_obj.identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.pgmpy_BN import Pgmpy_BN, build_meta_info\n",
    "def train_all(algo=\"chow-liu\", max_parents=1):\n",
    "    for i, relationship_obj in enumerate(schema.relationships):\n",
    "        sample_size = 10000000\n",
    "        relation = relationship_obj.identifier\n",
    "        df, meta_types, null_values, full_join_est = prep.generate_n_samples(\n",
    "                        sample_size, relationship_list=[relation], post_sampling_factor=10)\n",
    "        print(full_join_est)\n",
    "        print(len(df), len(df.columns))\n",
    "        print(meta_types)\n",
    "        meta_info = build_meta_info(df.columns)\n",
    "        bn = Pgmpy_BN(relation, meta_info, full_join_est)\n",
    "        model_path = f\"/home/ziniu.wzn/imdb-benchmark/BN_model/{i}_{algo}.pkl\"\n",
    "        print(model_path)\n",
    "        bn.build_from_data(df, algorithm=algo, max_parents=max_parents, ignore_cols=['id'], sample_size=200000)\n",
    "        pickle.dump(bn, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "        try:\n",
    "            BN.model = Bn.model.to_junction_tree()\n",
    "            model_path = f\"/home/ziniu.wzn/imdb-benchmark/BN_model/{i}_junction.pkl\"\n",
    "            pickle.dump(bn, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "        except:\n",
    "            print(\"This BN is not able to transform into junction tree, probably because it's not connected, just use BN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all(\"exact\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.parse_query_imdb import prepare_join_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble_location = \"/home/yuxing.hyx/dataset/imdb-benchmark/spn_ensembles/ensemble_join_3_budget_5_10000000.pkl\"\n",
    "ensemble_location = \"/home/yuxing.hyx/repository/imdb-benchmark/spn_ensembles/ensemble_relationships_imdb-light_10000000.pkl\"\n",
    "#query_filename = \"/home/ziniu.wzn/imdb-benchmark/cardinality/job_all.sql\"\n",
    "query_filename = \"/home/ziniu.wzn/BayesCard/Benchmark/IMDB/job-light.sql\"\n",
    "pairwise_rdc_path = \"/home/yuxing.hyx/repository/imdb-benchmark/spn_ensembles/pairwise_rdc.pkl\"\n",
    "parsed_queries, true = prepare_join_queries(ensemble_location, pairwise_rdc_path, query_filename, \n",
    "                                      join_3_rdc_based=False, true_card_exist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4050205.0,\n",
       " {'bn_index': 4,\n",
       "  'inverse': False,\n",
       "  'query': {'title.production_year': (1950.1, 1999.9),\n",
       "   'movie_companies.movie_companies_nn': 1,\n",
       "   'movie_companies.company_type_id': 2.0},\n",
       "  'expectation': ['title.mul_movie_keyword.movie_id']},\n",
       " {'bn_index': 3,\n",
       "  'inverse': False,\n",
       "  'query': {'title.production_year': (1950.1, 1999.9),\n",
       "   'movie_keyword.movie_keyword_nn': 1,\n",
       "   'movie_keyword.keyword_id': 398.0},\n",
       "  'expectation': []},\n",
       " {'bn_index': 3,\n",
       "  'inverse': True,\n",
       "  'query': {'title.production_year': (1950.1, 1999.9),\n",
       "   'movie_keyword.movie_keyword_nn': 1},\n",
       "  'expectation': []}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_queries[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_ensemble = dict()\n",
    "algo = \"clt\"\n",
    "for i in range(5):\n",
    "    with open(f\"/home/ziniu.wzn/imdb-benchmark/BN_model/{i}_{algo}.pkl\", \"rb\") as f:\n",
    "        bn = pickle.load(f)\n",
    "    bn_ensemble[i] = bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_ensemble[4].mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000000\n",
    "relation = \"movie_keyword.movie_id = title.id\"\n",
    "df, meta_types, null_values, full_join_est = prep.generate_n_samples(\n",
    "                sample_size, relationship_list=[relation], post_sampling_factor=10)\n",
    "print(full_join_est)\n",
    "print(len(df), len(df.columns))\n",
    "print(meta_types)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.pgmpy_BN import Pgmpy_BN, build_meta_info\n",
    "meta_info = build_meta_info(df.columns)\n",
    "bn = Pgmpy_BN(relation, meta_info, full_join_est)\n",
    "bn.build_from_data(df, algorithm=\"chow-liu\", max_parents=1, ignore_cols=['id'], sample_size=200000)\n",
    "model_path = f\"/home/ziniu.wzn/imdb-benchmark/BN_model/3_clt.pkl\"\n",
    "pickle.dump(bn, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fanout_values(bn, fanout_attrs):\n",
    "    print(fanout_attrs)\n",
    "    if len(fanout_attrs) == 1:\n",
    "        return bn.fanouts[fanout_attrs[0]]\n",
    "    else:\n",
    "        fanout_attrs_val = [list(self.fanouts[i]) for i in fanout_attrs]\n",
    "        return np.asarray(list(itertools.product(*fanout_attrs_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(bn, query, fanout_attrs, num_samples=1, coverage=None, return_prob=False, sample_size=10000):\n",
    "        \"\"\"\n",
    "        Calculating the expected value E[P(Q|F)*F]\n",
    "        Parameters\n",
    "        ----------\n",
    "        fanout_attrs: a list of fanout variables F, where we would like to compute the expectation\n",
    "        Rest parameters: the same as previous function .query().\n",
    "        \"\"\"\n",
    "        if fanout_attrs is None or len(fanout_attrs) == 0:\n",
    "            return bn.query(query, num_samples, coverage, return_prob, sample_size)\n",
    "        else:\n",
    "            query_prob = copy.deepcopy(query)\n",
    "            probsQ, _ = bn.query(query_prob, num_samples, coverage, True)\n",
    "            if probsQ == 0:\n",
    "                if return_prob:\n",
    "                    return 0, bn.nrows\n",
    "                else:\n",
    "                    return 0\n",
    "            print(f\"probsQ {probsQ}\")\n",
    "            \n",
    "            query, n_distinct = bn.query_decoding(query, coverage)\n",
    "            if query is None:\n",
    "                if return_prob:\n",
    "                    return 0, bn.nrows\n",
    "                else:\n",
    "                    return 0\n",
    "            print(query)\n",
    "            probsQF = bn.infer_machine.query(fanout_attrs, evidence=query).values\n",
    "            print(probsQF)\n",
    "            if any(np.isnan(probsQF)):\n",
    "                if return_prob:\n",
    "                    return 0, bn.nrows\n",
    "                else:\n",
    "                    return 0\n",
    "            else:\n",
    "                probsQF = probsQF / (np.sum(probsQF))\n",
    "            \n",
    "            print(np.sum(probsQF*get_fanout_values(bn, fanout_attrs)))\n",
    "            exp = np.sum(probsQF*get_fanout_values(bn, fanout_attrs)) * probsQ\n",
    "            if return_prob:\n",
    "                return exp, bn.nrows\n",
    "            else:\n",
    "                return exp*bn.nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "data = df.values\n",
    "for i in [2,3,4,5,6]:\n",
    "    if i == 2:\n",
    "        data_copy = copy.deepcopy(data[:, i])\n",
    "        data_copy[data_copy==0] = 1\n",
    "        print(df.columns[i], np.mean(1/data_copy))\n",
    "    else:\n",
    "        print(df.columns[i], np.mean(data[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.query({\"title.kind_id\": 7, \"title.production_year\": [2010, 2011, 2012]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.fanouts['title.mul_movie_info.movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for col in df.columns:\n",
    "    cols.append(col.replace(\".\", \"__\"))\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"a\":1, \"b\":2}\n",
    "b = {\"b\":2, \"a\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
