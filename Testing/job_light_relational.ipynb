{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('/home/ziniu.wzn/BayesCard')\n",
    "import pandas as pd\n",
    "import time\n",
    "import bz2\n",
    "import pickle\n",
    "import logging\n",
    "import ast\n",
    "\n",
    "from Models.pgmpy_BN import Pgmpy_BN\n",
    "from Evaluation.utils import parse_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_info_idx.movie_id = title.id\n",
      "movie_info.movie_id = title.id\n",
      "cast_info.movie_id = title.id\n",
      "movie_keyword.movie_id = title.id\n",
      "movie_companies.movie_id = title.id\n"
     ]
    }
   ],
   "source": [
    "from Schemas.imdb.schema import gen_job_light_imdb_schema\n",
    "from DataPrepare.join_data_preparation import JoinDataPreparator\n",
    "schema = gen_job_light_imdb_schema('/home/ziniu.wzn/imdb-benchmark')\n",
    "from DataPrepare.join_data_preparation import JoinDataPreparator\n",
    "hdf_path = \"/home/ziniu.wzn/imdb-benchmark/gen_single_light\"\n",
    "meta_data_path = hdf_path + '/meta_data.pkl'\n",
    "prep = JoinDataPreparator(meta_data_path, schema, max_table_data=20000000)\n",
    "for relationship_obj in schema.relationships:\n",
    "    print(relationship_obj.identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.pgmpy_BN import Pgmpy_BN, build_meta_info\n",
    "def train_all(algo=\"chow-liu\", max_parents=1):\n",
    "    for i, relationship_obj in enumerate(schema.relationships):\n",
    "        sample_size = 10000000\n",
    "        relation = relationship_obj.identifier\n",
    "        df, meta_types, null_values, full_join_est = prep.generate_n_samples(\n",
    "                        sample_size, relationship_list=[relation], post_sampling_factor=10)\n",
    "        print(full_join_est)\n",
    "        print(len(df), len(df.columns))\n",
    "        print(meta_types)\n",
    "        meta_info = build_meta_info(df.columns, null_values)\n",
    "        bn = Pgmpy_BN(relation, meta_info, full_join_est)\n",
    "        model_path = f\"/home/ziniu.wzn/imdb-benchmark/BN_model/{i}_{algo}.pkl\"\n",
    "        print(model_path)\n",
    "        bn.build_from_data(df, algorithm=algo, max_parents=max_parents, ignore_cols=['id'], sample_size=200000)\n",
    "        pickle.dump(bn, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            BN.model = Bn.model.to_junction_tree()\n",
    "            model_path = f\"/home/ziniu.wzn/imdb-benchmark/BN_model/{i}_junction.pkl\"\n",
    "            pickle.dump(bn, open(model_path, 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "        except:\n",
    "            print(\"This BN is not able to transform into junction tree, probably because it's not connected, just use BN\")\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_all(\"chow-liu\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.parse_query_imdb import prepare_join_queries\n",
    "#ensemble_location = \"/home/yuxing.hyx/dataset/imdb-benchmark/spn_ensembles/ensemble_join_3_budget_5_10000000.pkl\"\n",
    "ensemble_location = \"../Benchmark/IMDB/ensemble_loader.pkl\"\n",
    "#query_filename = \"/home/ziniu.wzn/imdb-benchmark/cardinality/job_all.sql\"\n",
    "query_filename = \"../Benchmark/IMDB/job-light.sql\"\n",
    "pairwise_rdc_path = \"../Benchmark/IMDB/pairwise_rdc.pkl\"\n",
    "parsed_queries, true = prepare_join_queries(ensemble_location, pairwise_rdc_path, query_filename, \n",
    "                                      join_3_rdc_based=False, true_card_exist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.BN_ensemble_model import BN_ensemble\n",
    "bn_ensemble = BN_ensemble(schema)\n",
    "algo = \"chow-liu\"\n",
    "distinct_mapping = dict()\n",
    "distinct_mapping['movie_keyword.keyword_id']={117: 8, 8200: 10, 398: 5, 7084: 20}\n",
    "distinct_mapping['movie_companies.company_id']={22956: 62}\n",
    "for i in range(5):\n",
    "    with open(f\"/home/ziniu.wzn/imdb-benchmark/BN_model/{i}_{algo}.pkl\", \"rb\") as f:\n",
    "        bn = pickle.load(f)\n",
    "        bn.infer_algo = \"progressive_sampling\"\n",
    "        bn.init_inference_method()\n",
    "        bn.n_distinct_mapping = distinct_mapping\n",
    "    bn_ensemble.bns[i] = bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = bn_ensemble.parse_query_all(parsed_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4050205.0,\n",
       "  {'bn_index': 4,\n",
       "   'inverse': False,\n",
       "   'expectation': ['title.mul_movie_info_idx.movie_id'],\n",
       "   'query': {'title.production_year': [0, 1, 12, 76],\n",
       "    'movie_companies.movie_companies_nn': 0,\n",
       "    'movie_companies.company_type_id': 1},\n",
       "   'n_distinct': {'title.production_year': [1.0, 1.0, 1.0, 1],\n",
       "    'movie_companies.movie_companies_nn': array([1]),\n",
       "    'movie_companies.company_type_id': array([1])}},\n",
       "  {'bn_index': 0,\n",
       "   'inverse': False,\n",
       "   'expectation': [],\n",
       "   'query': {'title.production_year': [0, 1, 13, 74],\n",
       "    'movie_info_idx.movie_info_idx_nn': 1,\n",
       "    'movie_info_idx.info_type_id': 4},\n",
       "   'n_distinct': {'title.production_year': [1.0, 1.0, 1.0, 1.0],\n",
       "    'movie_info_idx.movie_info_idx_nn': array([1]),\n",
       "    'movie_info_idx.info_type_id': array([1])}},\n",
       "  {'bn_index': 0,\n",
       "   'inverse': True,\n",
       "   'expectation': [],\n",
       "   'query': {'title.production_year': [0, 1, 13, 74],\n",
       "    'movie_info_idx.movie_info_idx_nn': 1},\n",
       "   'n_distinct': {'title.production_year': [1.0, 1.0, 1.0, 1.0],\n",
       "    'movie_info_idx.movie_info_idx_nn': array([1])}}],\n",
       " 47)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[2], true[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_ensemble.cardinality(queries[2], sample_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Benchmark/IMDB/job-light.sql\", \"rb\") as f:\n",
    "    real_query = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "latency = []\n",
    "q_error = []\n",
    "for i, q in enumerate(queries):\n",
    "    tic = time.time()\n",
    "    try:\n",
    "        pred = bn_ensemble.cardinality(q)\n",
    "    except:\n",
    "        print(\"invalid\")\n",
    "        #this query itself is invalid or it is not recognizable by the learnt BN\n",
    "        continue\n",
    "    latency.append(time.time()-tic)\n",
    "    if pred is None or pred <= 1:\n",
    "        pred = 1\n",
    "    error = max(pred/true[i], true[i]/pred)\n",
    "    print(real_query[i])\n",
    "    print(f\"true cardinality {true[i]}, predicted {pred} with q-error {error}\")\n",
    "    q_error.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 100]:\n",
    "    print(np.percentile(q_error, i))\n",
    "print(np.mean(latency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50, 90, 95, 100]:\n",
    "    print(np.percentile(q_error, i))\n",
    "print(np.mean(latency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
