{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import tools\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from model import Single_BN\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import scipy.stats\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate, infer_discrete\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_table(nrows = 10000):\n",
    "    \"\"\"\n",
    "    Create some toy table for evaluation and debug purposes\n",
    "    \"\"\"\n",
    "    vocab = ['a', 'b', 'c', 'd', 'e']\n",
    "    attr1 = np.random.randint(10, size=nrows)\n",
    "    attr2 = np.random.randint(3, size=nrows)+10\n",
    "    attr3 = np.random.normal(3, 100, size=nrows)\n",
    "    attr4 = attr1+attr2+np.random.normal(0, 1, size=nrows)\n",
    "    attr5 = attr3*2.5+1.5\n",
    "    dataset = pd.DataFrame({'attr1': attr1, 'attr2': attr2, 'attr3': attr3, 'attr4': attr4, 'attr5': attr5})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM(data, K=1, lr=0.01):\n",
    "    data = torch.tensor(data.values).type(torch.FloatTensor)\n",
    "    K = 1\n",
    "    @config_enumerate\n",
    "    def model(data):\n",
    "        # Global variables.\n",
    "        weights = pyro.sample('weights', dist.Dirichlet(0.5 * torch.ones(K)))\n",
    "        with pyro.plate('components', K):\n",
    "            scales = pyro.sample('scales', dist.LogNormal(0., 20.))\n",
    "            locs = pyro.sample('locs', dist.Normal(0., 10.))\n",
    "\n",
    "        with pyro.plate('data', len(data)):\n",
    "            # Local variables.\n",
    "            assignment = pyro.sample('assignment', dist.Categorical(weights))\n",
    "            pyro.sample('obs', dist.Normal(locs[assignment], scales[assignment]), obs=data)\n",
    "    \n",
    "    optim = pyro.optim.Adam({'lr': lr, 'betas': [0.8, 0.99]})\n",
    "    elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "    \n",
    "    def init_loc_fn(site):\n",
    "        if site[\"name\"] == \"weights\":\n",
    "            # Initialize weights to uniform.\n",
    "            return torch.ones(K) / K\n",
    "        if site[\"name\"] == \"scales\":\n",
    "            return torch.tensor([(data.var() / 2).sqrt()]*K)\n",
    "        if site[\"name\"] == \"locs\":\n",
    "            return data[torch.multinomial(torch.ones(len(data)) / len(data), K)]\n",
    "        raise ValueError(site[\"name\"])\n",
    "\n",
    "    def initialize(seed):\n",
    "        global global_guide, svi\n",
    "        pyro.set_rng_seed(seed)\n",
    "        pyro.clear_param_store()\n",
    "        global_guide = AutoDelta(poutine.block(model, expose=['weights', 'locs', 'scales']),\n",
    "                                 init_loc_fn=init_loc_fn)\n",
    "        svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "        return svi.loss(model, global_guide, data)\n",
    "\n",
    "    # Choose the best among 100 random initializations.\n",
    "    loss, seed = min((initialize(seed), seed) for seed in range(100))\n",
    "    initialize(seed)\n",
    "    print('seed = {}, initial_loss = {}'.format(seed, loss))\n",
    "    gradient_norms = defaultdict(list)\n",
    "    for name, value in pyro.get_param_store().named_parameters():\n",
    "        value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "    losses = []\n",
    "    for i in range(50):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "        print('.' if i % 10 else '\\n', end='')\n",
    "        \n",
    "    map_estimates = global_guide(data)\n",
    "    weights = map_estimates['weights']\n",
    "    locs = map_estimates['locs']\n",
    "    scales = map_estimates['scales']\n",
    "    print('weights = {}'.format(weights.data.numpy()))\n",
    "    print('locs = {}'.format(locs.data.numpy()))\n",
    "    print('scale = {}'.format(scales.data.numpy()))\n",
    "    return weights.data.numpy(), locs.data.numpy(), scales.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = toy_table()\n",
    "GMM(df['attr3'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['attr3'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_categorical(data):\n",
    "    n_cat = data.nunique()\n",
    "    data = torch.tensor(data.values).type(torch.FloatTensor)\n",
    "    def model(data):\n",
    "        # Global variables.\n",
    "        probs = pyro.sample('probs', dist.Dirichlet(0.5 * torch.ones(n_cat)))\n",
    "        with pyro.plate('data', len(data)):\n",
    "            # Local variables.\n",
    "            pyro.sample('obs', dist.Categorical(probs), obs=data)\n",
    "            \n",
    "    optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "    elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "    \n",
    "    def init_loc_fn(site):\n",
    "        if site[\"name\"] == \"probs\":\n",
    "            # Initialize probs to uniform.\n",
    "            return torch.ones(n_cat) / n_cat\n",
    "        raise ValueError(site[\"name\"])\n",
    "    \n",
    "    def initialize(seed):\n",
    "        global global_guide, svi\n",
    "        pyro.set_rng_seed(seed)\n",
    "        pyro.clear_param_store()\n",
    "        global_guide = AutoDelta(poutine.block(model, expose=['probs']),\n",
    "                                 init_loc_fn=init_loc_fn)\n",
    "        svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "        return svi.loss(model, global_guide, data)\n",
    "    \n",
    "    loss, seed = min((initialize(seed), seed) for seed in range(100))\n",
    "    initialize(seed)\n",
    "    print('seed = {}, initial_loss = {}'.format(seed, loss))\n",
    "    gradient_norms = defaultdict(list)\n",
    "    for name, value in pyro.get_param_store().named_parameters():\n",
    "        value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "    losses = []\n",
    "    for i in range(50):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "        print('.' if i % 10 else '\\n', end='')\n",
    "        \n",
    "    map_estimates = global_guide(data)\n",
    "    probs = map_estimates['probs']\n",
    "    print('probs = {}'.format(probs.data.numpy()))\n",
    "    return probs.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical(data):\n",
    "    n_cat = data.nunique()\n",
    "    data = torch.tensor(data.values).type(torch.FloatTensor)\n",
    "    def model(data):\n",
    "        # Global variables.\n",
    "        probs = pyro.sample('probs', dist.Dirichlet(0.5 * torch.ones(n_cat)))\n",
    "        with pyro.plate('data', len(data)):\n",
    "            # Local variables.\n",
    "            pyro.sample('obs', dist.Categorical(probs), obs=data)\n",
    "    optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "    elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "    \n",
    "    def init_loc_fn(site):\n",
    "        if site[\"name\"] == \"probs\":\n",
    "            # Initialize probs to uniform.\n",
    "            return torch.ones(n_cat) / n_cat\n",
    "        raise ValueError(site[\"name\"])\n",
    "    \n",
    "    def initialize(seed):\n",
    "        global global_guide, svi\n",
    "        pyro.set_rng_seed(seed)\n",
    "        pyro.clear_param_store()\n",
    "        global_guide = AutoDelta(poutine.block(model, expose=['probs']),\n",
    "                                 init_loc_fn=init_loc_fn)\n",
    "        svi = SVI(model, global_guide, optim, loss=elbo)\n",
    "        return svi.loss(model, global_guide, data)\n",
    "    \n",
    "    loss, seed = min((initialize(seed), seed) for seed in range(100))\n",
    "    initialize(seed)\n",
    "    print('seed = {}, initial_loss = {}'.format(seed, loss))\n",
    "    gradient_norms = defaultdict(list)\n",
    "    for name, value in pyro.get_param_store().named_parameters():\n",
    "        value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "    losses = []\n",
    "    for i in range(50):\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "        print('.' if i % 10 else '\\n', end='')\n",
    "        \n",
    "    map_estimates = global_guide(data)\n",
    "    probs = map_estimates['probs']\n",
    "    print('probs = {}'.format(probs.data.numpy()))\n",
    "    return probs.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuwu/anaconda3/envs/env/lib/python3.7/site-packages/pyro/infer/traceenum_elbo.py:310: UserWarning: TraceEnum_ELBO found no sample sites configured for enumeration. If you want to enumerate sites, you need to @config_enumerate or set infer={\"enumerate\": \"sequential\"} or infer={\"enumerate\": \"parallel\"}? If you do not want to enumerate, consider using Trace_ELBO instead.\n",
      "  warnings.warn('TraceEnum_ELBO found no sample sites configured for enumeration. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 0, initial_loss = 23018.04296875\n",
      "\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........probs = [0.10251568 0.09592286 0.09830005 0.09840512 0.10396029 0.10000031\n",
      " 0.0996993  0.09639328 0.09889549 0.10590766]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.10251568, 0.09592286, 0.09830005, 0.09840512, 0.10396029,\n",
       "       0.10000031, 0.0996993 , 0.09639328, 0.09889549, 0.10590766],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical(df['attr1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['attr1'])==pd.core.series.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.ones(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
