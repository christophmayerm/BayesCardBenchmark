{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import sys\n",
    "sys.path.append('/Users/ziniuwu/Desktop/research/BayesCard')\n",
    "from Pgmpy.factors import factor_product\n",
    "from Pgmpy.models import BayesianModel, JunctionTree\n",
    "from Pgmpy.inference.EliminationOrder import (\n",
    "    WeightedMinFill,\n",
    "    MinNeighbors,\n",
    "    MinFill,\n",
    "    MinWeight,\n",
    ")\n",
    "from Pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "from Models.pgmpy_BN import Pgmpy_BN\n",
    "from Testing.toy_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableElimination(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        model.check_model()\n",
    "\n",
    "        if isinstance(model, JunctionTree):\n",
    "            self.variables = set(chain(*model.nodes()))\n",
    "        else:\n",
    "            self.variables = model.nodes()\n",
    "\n",
    "        self.cardinality = {}\n",
    "        self.factors = defaultdict(list)\n",
    "\n",
    "        if isinstance(model, BayesianModel):\n",
    "            self.state_names_map = {}\n",
    "            for node in model.nodes():\n",
    "                cpd = model.get_cpds(node)\n",
    "                if isinstance(cpd, TabularCPD):\n",
    "                    self.cardinality[node] = cpd.variable_card\n",
    "                    cpd = cpd.to_factor()\n",
    "                for var in cpd.scope():\n",
    "                    self.factors[var].append(cpd)\n",
    "                self.state_names_map.update(cpd.no_to_name)\n",
    "\n",
    "        elif isinstance(model, JunctionTree):\n",
    "            self.cardinality = model.get_cardinality()\n",
    "\n",
    "            for factor in model.get_factors():\n",
    "                for var in factor.variables:\n",
    "                    self.factors[var].append(factor)\n",
    "        self.root = self.get_root()\n",
    "\n",
    "        \n",
    "    def get_root(self):\n",
    "        \"\"\"Returns the network's root node.\"\"\"\n",
    "        def find_root(graph, node):\n",
    "            predecessor = next(self.model.predecessors(node), None)\n",
    "            if predecessor:\n",
    "                root = find_root(graph, predecessor)\n",
    "            else:\n",
    "                root = node\n",
    "            return root\n",
    "\n",
    "        return find_root(self, list(self.model.nodes)[0])\n",
    "    \n",
    "    \n",
    "    def steiner_tree(self, nodes):\n",
    "        \"\"\"Returns the minimal part of the tree that contains a set of nodes.\"\"\"\n",
    "        sub_nodes = set()\n",
    "\n",
    "        def walk(node, path):\n",
    "\n",
    "            if len(nodes) == 0:\n",
    "                return\n",
    "\n",
    "            if node in nodes:\n",
    "                sub_nodes.update(path + [node])\n",
    "                nodes.remove(node)\n",
    "\n",
    "            for child in self.model.successors(node):\n",
    "                walk(child, path + [node])\n",
    "        walk(self.root, [])\n",
    "        sub_graph = self.model.subgraph(sub_nodes)\n",
    "        sub_graph.cardinalities = defaultdict(int)\n",
    "        for node in sub_graph.nodes:\n",
    "            sub_graph.cardinalities[node] = self.model.cardinalities[node]\n",
    "        return sub_graph\n",
    "    \n",
    "    \n",
    "    def _get_working_factors(self, variables, evidence):\n",
    "        \"\"\"\n",
    "        Uses the evidence given to the query methods to modify the factors before running\n",
    "        the variable elimination algorithm.\n",
    "        Parameters\n",
    "        ----------\n",
    "        evidence: dict\n",
    "            Dict of the form {variable: state}\n",
    "        Returns\n",
    "        -------\n",
    "        dict: Modified working factors.\n",
    "        \"\"\"\n",
    "        useful_var = variables + list(evidence.keys())\n",
    "        sub_graph_model = self.steiner_tree(useful_var)\n",
    "        variables_sub_graph = set(sub_graph_model.nodes)\n",
    "        \n",
    "        working_factors = dict()\n",
    "        for node in sub_graph_model.nodes:\n",
    "            working_factors[node] = set()\n",
    "            for factor in self.factors[node]:\n",
    "                if set(factor.variables).issubset(variables_sub_graph):\n",
    "                    working_factors[node].add((factor, None))\n",
    "\n",
    "        # Dealing with evidence. Reducing factors over it before VE is run.\n",
    "        if evidence:\n",
    "            for evidence_var in evidence:\n",
    "                for factor, origin in working_factors[evidence_var]:\n",
    "                    factor_reduced = factor.reduce(\n",
    "                        [(evidence_var, evidence[evidence_var])], inplace=False\n",
    "                    )\n",
    "                    for var in factor_reduced.scope():\n",
    "                        if var in working_factors:\n",
    "                            working_factors[var].remove((factor, origin))\n",
    "                            working_factors[var].add((factor_reduced, evidence_var))\n",
    "                if type(evidence[evidence_var]) != list:\n",
    "                    del working_factors[evidence_var]\n",
    "        return working_factors, sub_graph_model\n",
    "    \n",
    "    def _get_elimination_order(\n",
    "        self, variables, evidence, model=None, elimination_order=\"minfill\", show_progress=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Deals with all elimination order parameters given to _variable_elimination method\n",
    "        and returns a list of variables that are to be eliminated\n",
    "        Parameters\n",
    "        ----------\n",
    "        elimination_order: str or list\n",
    "        Returns\n",
    "        -------\n",
    "        list: A list of variables names in the order they need to be eliminated.\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        if isinstance(model, JunctionTree):\n",
    "            all_variables = set(chain(*model.nodes()))\n",
    "        else:\n",
    "            all_variables = model.nodes()\n",
    "        \n",
    "        not_evidence_eliminate = []\n",
    "        if evidence is not None:\n",
    "            for key in evidence:\n",
    "                if type(evidence[key]) != list:\n",
    "                    not_evidence_eliminate.append(key)\n",
    "        to_eliminate = (\n",
    "            set(all_variables)\n",
    "            - set(variables)\n",
    "            - set(not_evidence_eliminate)\n",
    "        )\n",
    "\n",
    "        # Step 1: If elimination_order is a list, verify it's correct and return.\n",
    "        if hasattr(elimination_order, \"__iter__\") and (\n",
    "            not isinstance(elimination_order, str)\n",
    "        ):\n",
    "            if any(\n",
    "                var in elimination_order\n",
    "                for var in set(variables).union(\n",
    "                    set(evidence.keys() if evidence else [])\n",
    "                )\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Elimination order contains variables which are in\"\n",
    "                    \" variables or evidence args\"\n",
    "                )\n",
    "            else:\n",
    "                return elimination_order\n",
    "\n",
    "        # Step 2: If elimination order is None or a Markov model, return a random order.\n",
    "        elif (elimination_order is None) or (not isinstance(model, BayesianModel)):\n",
    "            return to_eliminate\n",
    "\n",
    "        # Step 3: If elimination order is a str, compute the order using the specified heuristic.\n",
    "        elif isinstance(elimination_order, str) and isinstance(\n",
    "            model, BayesianModel\n",
    "        ):\n",
    "            heuristic_dict = {\n",
    "                \"weightedminfill\": WeightedMinFill,\n",
    "                \"minneighbors\": MinNeighbors,\n",
    "                \"minweight\": MinWeight,\n",
    "                \"minfill\": MinFill,\n",
    "            }\n",
    "            elimination_order = heuristic_dict[elimination_order.lower()](\n",
    "                model\n",
    "            ).get_elimination_order(nodes=to_eliminate, show_progress=show_progress)\n",
    "            return elimination_order\n",
    "    \n",
    "    def _variable_elimination(\n",
    "        self,\n",
    "        variables,\n",
    "        operation,\n",
    "        evidence=None,\n",
    "        elimination_order=\"minfill\",\n",
    "        joint=True,\n",
    "        show_progress=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of a generalized variable elimination.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        variables: list, array-like\n",
    "            variables that are not to be eliminated.\n",
    "\n",
    "        operation: str ('marginalize' | 'maximize')\n",
    "            The operation to do for eliminating the variable.\n",
    "\n",
    "        evidence: dict\n",
    "            a dict key, value pair as {var: state_of_var_observed}\n",
    "            None if no evidence\n",
    "\n",
    "        elimination_order: str or list (array-like)\n",
    "            If str: Heuristic to use to find the elimination order.\n",
    "            If array-like: The elimination order to use.\n",
    "            If None: A random elimination order is used.\n",
    "        \"\"\"\n",
    "        # Step 1: Deal with the input arguments.\n",
    "        if isinstance(variables, str):\n",
    "            raise TypeError(\"variables must be a list of strings\")\n",
    "        if isinstance(evidence, str):\n",
    "            raise TypeError(\"evidence must be a list of strings\")\n",
    "\n",
    "        # Dealing with the case when variables is not provided.\n",
    "        if not variables:\n",
    "            all_factors = []\n",
    "            for factor_li in self.factors.values():\n",
    "                all_factors.extend(factor_li)\n",
    "            if joint:\n",
    "                return factor_product(*set(all_factors))\n",
    "            else:\n",
    "                return set(all_factors)\n",
    "\n",
    "        # Step 2: Prepare data structures to run the algorithm.\n",
    "        eliminated_variables = set()\n",
    "        # Get working factors and elimination order\n",
    "        tic = time.time()\n",
    "        working_factors, sub_graph_model = self._get_working_factors(variables, evidence)\n",
    "        toc = time.time()\n",
    "        print(f\"getting working factors takes {toc-tic} secs\")\n",
    "        elimination_order = self._get_elimination_order(\n",
    "            variables, evidence, sub_graph_model, elimination_order, show_progress=show_progress\n",
    "        )\n",
    "        print(f\"getting elimination orders takes {time.time()-toc} secs\")\n",
    "        # Step 3: Run variable elimination\n",
    "        if show_progress:\n",
    "            pbar = tqdm(elimination_order)\n",
    "        else:\n",
    "            pbar = elimination_order\n",
    "\n",
    "        for var in pbar:\n",
    "            tic = time.time()\n",
    "            print(var)\n",
    "            if show_progress:\n",
    "                pbar.set_description(\"Eliminating: {var}\".format(var=var))\n",
    "            # Removing all the factors containing the variables which are\n",
    "            # eliminated (as all the factors should be considered only once)\n",
    "            factors = [\n",
    "                factor\n",
    "                for factor, _ in working_factors[var]\n",
    "                if not set(factor.variables).intersection(eliminated_variables)\n",
    "            ]\n",
    "            if var == \"iYearwrk\":\n",
    "                print(factors)\n",
    "            phi = factor_product(*factors)\n",
    "            phi = getattr(phi, operation)([var], inplace=False)\n",
    "            del working_factors[var]\n",
    "            for variable in phi.variables:\n",
    "                if variable in working_factors:\n",
    "                    working_factors[variable].add((phi, var))\n",
    "            eliminated_variables.add(var)\n",
    "            print(f\"eliminating {var} takes {time.time()-tic} secs\")\n",
    "            \n",
    "        # Step 4: Prepare variables to be returned.\n",
    "        tic = time.time()\n",
    "        final_distribution = set()\n",
    "        for node in working_factors:\n",
    "            for factor, origin in working_factors[node]:\n",
    "                if not set(factor.variables).intersection(eliminated_variables):\n",
    "                    final_distribution.add((factor, origin))\n",
    "        final_distribution = [factor for factor, _ in final_distribution]\n",
    "        print(final_distribution)\n",
    "        print(f\"the rest takes {time.time()-tic} secs\")\n",
    "        if joint:\n",
    "            if isinstance(self.model, BayesianModel):\n",
    "                return factor_product(*final_distribution).normalize(inplace=False)\n",
    "            else:\n",
    "                return factor_product(*final_distribution)\n",
    "        else:\n",
    "            query_var_factor = {}\n",
    "            for query_var in variables:\n",
    "                phi = factor_product(*final_distribution)\n",
    "                query_var_factor[query_var] = phi.marginalize(\n",
    "                    list(set(variables) - set([query_var])), inplace=False\n",
    "                ).normalize(inplace=False)\n",
    "            print(f\"the rest takes {time.time()-tic} secs\")\n",
    "            return query_var_factor\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        variables,\n",
    "        evidence=None,\n",
    "        elimination_order=\"MinFill\",\n",
    "        joint=True,\n",
    "        show_progress=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        variables: list\n",
    "            list of variables for which you want to compute the probability\n",
    "\n",
    "        evidence: dict\n",
    "            a dict key, value pair as {var: state_of_var_observed}\n",
    "            None if no evidence\n",
    "\n",
    "        elimination_order: list\n",
    "            order of variable eliminations (if nothing is provided) order is\n",
    "            computed automatically\n",
    "\n",
    "        joint: boolean (default: True)\n",
    "            If True, returns a Joint Distribution over `variables`.\n",
    "            If False, returns a dict of distributions over each of the `variables`.\n",
    "        \"\"\"\n",
    "        common_vars = set(evidence if evidence is not None else []).intersection(\n",
    "            set(variables)\n",
    "        )\n",
    "        if common_vars:\n",
    "            raise ValueError(\n",
    "                f\"Can't have the same variables in both `variables` and `evidence`. Found in both: {common_vars}\"\n",
    "            )\n",
    "\n",
    "        return self._variable_elimination(\n",
    "            variables=variables,\n",
    "            operation=\"marginalize\",\n",
    "            evidence=evidence,\n",
    "            elimination_order=elimination_order,\n",
    "            joint=joint,\n",
    "            show_progress=show_progress,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('check_points/Census_chow-liu.pkl', 'rb') as f:\n",
    "    BN = pickle.load(f)\n",
    "with open('check_points/Census_junction.pkl', 'rb') as f:\n",
    "    BN_J = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN.model.cardinalities = BN.model.get_cardinality()\n",
    "ve = VariableElimination(BN.model)\n",
    "factors = ve.factors\n",
    "cpds = BN.model.cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Internal error in pre-inference rewriting pass encountered during compilation of function \"reduce\" due to: Constant inference not possible for: call $42load_global.2($48binary_subscr.5, func=$42load_global.2, args=[Var($48binary_subscr.5, DiscreteFactor.py:306)], kws=(), vararg=None)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 306:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "            raise TypeError(\n",
      "                \"values: Expected type list of tuples, get type {type}\", type(values[0])\n",
      "                ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: Untyped global name 'isinstance': cannot determine Numba type of <class 'builtin_function_or_method'>\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (318)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (330)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Internal error in pre-inference rewriting pass encountered during compilation of function \"reduce\" due to: Constant inference not possible for: call $42load_global.2($48binary_subscr.5, func=$42load_global.2, args=[Var($48binary_subscr.5, DiscreteFactor.py:306)], kws=(), vararg=None)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 306:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "            raise TypeError(\n",
      "                \"values: Expected type list of tuples, get type {type}\", type(values[0])\n",
      "                ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: Untyped global name 'isinstance': cannot determine Numba type of <class 'builtin_function_or_method'>\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (318)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  @jit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (330)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "f, s =ve._get_working_factors([\"iAvail\"], {\"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.keys())\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting working factors takes 0.0626220703125 secs\n",
      "getting elimination orders takes 0.0015330314636230469 secs\n",
      "iFertil\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cda549d241e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m q = ve.query([\"iAvail\"], {\"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0},\n\u001b[0;32m----> 3\u001b[0;31m             elimination_order=\"weightedminfill\")\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6e8b2209728d>\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, variables, evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0melimination_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melimination_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mjoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         )\n",
      "\u001b[0;32m<ipython-input-3-6e8b2209728d>\u001b[0m in \u001b[0;36m_variable_elimination\u001b[0;34m(self, variables, operation, evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iYearwrk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mworking_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/BayesCard/Pgmpy/factors/base.py\u001b[0m in \u001b[0;36mfactor_product\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;34m\"All the args are expected to be instances of the same factor class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         )\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mphi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mphi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/BayesCard/Pgmpy/factors/base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(phi1, phi2)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;34m\"All the args are expected to be instances of the same factor class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         )\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mphi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mphi1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mphi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py\u001b[0m in \u001b[0;36mproduct\u001b[0;34m(self, phi1, inplace)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0mnew_var_card\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                 phi.cardinality = np.append(\n\u001b[1;32m    457\u001b[0m                     \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_var_card\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextra_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOmitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0margtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36mtypeof_pyval\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# can save a couple µs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPurpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/typing/typeof.py\u001b[0m in \u001b[0;36mtypeof\u001b[0;34m(val, purpose)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Note the behaviour for Purpose.argument must match _typeof.c.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TypeofContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpurpose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypeof_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mty\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         msg = _termcolor.errmsg(\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/typing/typeof.py\u001b[0m in \u001b[0;36m_typeof_set\u001b[0;34m(val, c)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypeof_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreflected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtypeof_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/types/abstract.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/types/containers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, reflected)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreflected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUndefined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreflected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "q = ve.query([\"iAvail\"], {\"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0},\n",
    "            elimination_order=\"weightedminfill\")\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ve = VariableElimination(BN.model)\n",
    "BN.infer_machine = ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(BN, open('check_points/Census_chow-liu.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN.query({\"iAvail\": 0, \"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.cardinality_estimation import parse_query_single_table\n",
    "from time import perf_counter\n",
    "def evaluate_cardinality(BN, query_path):\n",
    "    # read all queries\n",
    "    with open(query_path) as f:\n",
    "        queries = f.readlines()\n",
    "    latencies = []\n",
    "    q_errors = []\n",
    "    for query_no, query_str in enumerate(queries):\n",
    "        cardinality_true = int(query_str.split(\"||\")[-1])\n",
    "        query_str = query_str.split(\"||\")[0]\n",
    "        print(f\"Predicting cardinality for query {query_no}: {query_str}\")\n",
    "        \n",
    "        query = parse_query_single_table(query_str.strip(), BN)\n",
    "        card_start_t = perf_counter()\n",
    "        print(query)\n",
    "        try:\n",
    "            cardinality_predict = BN.query(query)\n",
    "        except:\n",
    "            continue\n",
    "        if cardinality_predict is None:\n",
    "            continue\n",
    "        card_end_t = perf_counter()\n",
    "        latency_ms = (card_end_t - card_start_t) * 1000\n",
    "        if cardinality_predict == 0 and cardinality_true == 0:\n",
    "            q_error = 1.0\n",
    "        elif cardinality_predict == 0:\n",
    "            cardinality_predict = 1\n",
    "        elif cardinality_true == 0:\n",
    "            cardinality_true = 1\n",
    "\n",
    "        q_error = max(cardinality_predict / cardinality_true, cardinality_true / cardinality_predict)\n",
    "        print(f\"latency: {latency_ms} and error: {q_error}\")\n",
    "        latencies.append(latency_ms)\n",
    "        q_errors.append(q_error)\n",
    "    return latencies, q_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50,90,95,99,100]:\n",
    "    print(np.percentile(q_errors, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
