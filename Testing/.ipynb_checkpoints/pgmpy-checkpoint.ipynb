{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmpy\n",
    "from pgmpy.models import BayesianModel\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/ziniuwu/Desktop/research/BayesNet')\n",
    "from Structure.model import BN_Single\n",
    "from Testing.toy_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pgmpy_BN(BN_Single):\n",
    "    \"\"\"\n",
    "    Build a single Bayesian Network for a single table using pgmpy\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, table_name, method='Pome', debug=True, infer_algo=None):\n",
    "        \"\"\"\n",
    "        infer_algo: inference method, choose between 'exact', 'BP'\n",
    "        \"\"\"\n",
    "        BN_Single.__init__(self, table_name, method, debug)\n",
    "        self.infer_algo = infer_algo\n",
    "\n",
    "\n",
    "    def build_from_data(self, dataset, attr_type=None, n_mcv=30, n_bins=60, ignore_cols=['id'],\n",
    "                        algorithm=\"chow-liu\", drop_na=True, max_parents=-1, root=0, n_jobs=8):\n",
    "        \"\"\" Build the Pomegranate model from data, including structure learning and paramter learning\n",
    "            ::Param:: dataset: pandas.dataframe\n",
    "                      attr_type: type of attributes (binary, discrete or continuous)\n",
    "                      n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                      n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "            for other parameters, pomegranate gives a detailed explaination:\n",
    "            https://pomegranate.readthedocs.io/en/latest/BayesianNetwork.html\n",
    "        \"\"\"\n",
    "        self.algorithm = algorithm\n",
    "        if algorithm != \"junction\":\n",
    "            discrete_table = self.learn_model_structure(dataset, attr_type, n_mcv, n_bins, ignore_cols, algorithm,\n",
    "                                                        drop_na, max_parents, root, n_jobs, return_dataset=True)\n",
    "        else:\n",
    "            discrete_table = self.learn_model_structure(dataset, attr_type, n_mcv, n_bins, ignore_cols, 'exact',\n",
    "                                                        drop_na, max_parents, root, n_jobs, return_dataset=True)\n",
    "\n",
    "        spec = []\n",
    "        orphans = []\n",
    "        for i, parents in enumerate(self.structure):\n",
    "            for p in parents:\n",
    "                spec.append((self.node_names[p], self.node_names[i]))\n",
    "            if not parents:\n",
    "                orphans.append(self.node_names[i])\n",
    "        if self.debug:\n",
    "            print(f\"Model spec{spec}\")\n",
    "        self.model = BayesianModel(spec)\n",
    "        for o in orphans:\n",
    "            self.model.add_node(o)\n",
    "        print('calling pgm.BayesianModel.fit...')\n",
    "        t = time.time()\n",
    "        self.model.fit(discrete_table)\n",
    "        if algorithm == \"junction\":\n",
    "            self.model = self.model.to_junction_tree()\n",
    "        print(f\"done, took {time.time() - t} secs.\")\n",
    "        self.init_inference_method()\n",
    "\n",
    "\n",
    "    def init_inference_method(self):\n",
    "        \"\"\"\n",
    "        Initial the inference method for query\n",
    "        \"\"\"\n",
    "        if self.infer_algo is None:\n",
    "            if self.algorithm == \"chow-liu\":\n",
    "                self.infer_algo = \"exact\"\n",
    "            else:\n",
    "                self.infer_algo = \"BP\"\n",
    "\n",
    "        if self.infer_algo == \"exact\":\n",
    "            from pgmpy.inference import VariableElimination\n",
    "            self.infer_machine = VariableElimination(self.model)\n",
    "        elif self.infer_algo == \"BP\":\n",
    "            from pgmpy.inference import BeliefPropagation\n",
    "            self.infer_machine = BeliefPropagation(self.model)\n",
    "            self.infer_machine.calibrate()\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "            \n",
    "    def one_iter_of_infer(self, query, n_distinct):\n",
    "        \"\"\"Performance a BP in random order.\n",
    "           This adapts the BP implemented in pgympy package itself.\n",
    "        \"\"\"\n",
    "        copy_query = copy.deepcopy(query)\n",
    "        sampling_order = copy.deepcopy(self.node_names)\n",
    "        np.random.shuffle(sampling_order)\n",
    "        \n",
    "        p_estimate = 1\n",
    "        for attr in sampling_order:\n",
    "            if attr in copy_query:\n",
    "                print(attr)\n",
    "                val = copy_query.pop(attr)\n",
    "                p = self.infer_machine.query([attr], evidence=copy_query).values[val]*n_distinct[attr]\n",
    "                if np.isnan(p):\n",
    "                    p_estimate = 0\n",
    "                    break\n",
    "                p_estimate *= p\n",
    "        return p_estimate\n",
    "        \n",
    "            \n",
    "    def infer_point_query(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Loopy belief propagation. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:x, Y:y, Z:z}\n",
    "                     x,y,z can only be a single value\n",
    "                     num_samples: how many times to run inference, only useful for approaximate algo\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "        \"\"\"\n",
    "        nrows = self.nrows\n",
    "        n_distinct = dict()\n",
    "        for attr in query:\n",
    "            encode_value = self.apply_encoding_to_value(query[attr], attr)\n",
    "            n_distinct[attr] = self.apply_ndistinct_to_value(encode_value, query[attr], attr)\n",
    "            query[attr] = encode_value\n",
    "            \n",
    "        if self.infer_algo = \"exact\" or self.num_samples == 1:\n",
    "            #Using topological order to infer probability\n",
    "            sampling_order = []\n",
    "            while len(sampling_order) < len(self.structure):\n",
    "                for i, deps in enumerate(self.structure):\n",
    "                    if i in sampling_order:\n",
    "                        continue  # already ordered\n",
    "                    if all(d in sampling_order for d in deps):\n",
    "                        sampling_order.append(i)\n",
    "            sampling_order = [self.node_names[i] for i in sampling_order]\n",
    "            print(sampling_order)\n",
    "            \n",
    "            p_estimate = 1\n",
    "            for attr in sampling_order:\n",
    "                if attr in query:\n",
    "                    print(attr)\n",
    "                    val = query.pop(attr)\n",
    "                    p = self.infer_machine.query([attr], evidence=query).values[val]*n_distinct[attr]\n",
    "                    if np.isnan(p):\n",
    "                        p_estimate = 0\n",
    "                        break\n",
    "                    p_estimate *= p\n",
    "                        \n",
    "        else:\n",
    "            p_estimates = []\n",
    "            for i in range(num_samples):\n",
    "                p_estimates.append(self.one_iter_of_infer(query, n_distinct))\n",
    "            p_estimate = sum(p_estimates)/num_samples\n",
    "        \n",
    "        if return_prob:\n",
    "            return (p_estimate, nrows)\n",
    "        return round(p_estimate * nrows)\n",
    "    \n",
    "    \n",
    "    def infer_range_query_BP(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Loopy belief propagation. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:[x], Y:[y], Z:[z]}\n",
    "                     x,y,z can only be set of single value\n",
    "                     num_samples: how many times to run inference. Since Loopy belief propagation is sometime\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "           LBP for estimating range query can be really slow\n",
    "        \"\"\"\n",
    "        p_estimate = 0\n",
    "        for query_tuple in cartesian_product(query):\n",
    "            point_query = dict()\n",
    "            i = 0\n",
    "            for attr in query:\n",
    "                point_query[attr] = query_tuple[i]\n",
    "                i += 1\n",
    "            p_estimate += self.infer_point_query_BP(point_query, return_prob=True)[0]\n",
    "        \n",
    "        return p_estimate*self.nrows\n",
    "\n",
    "\n",
    "    def infer_point_query_exact(self, query, return_prob=False):\n",
    "        nrows = self.nrows\n",
    "        n_distinct = dict()\n",
    "        for attr in query:\n",
    "            encode_value = self.apply_encoding_to_value(query[attr], attr)\n",
    "            n_distinct[attr] = self.apply_ndistinct_to_value(encode_value, query[attr], attr)\n",
    "            query[attr] = encode_value\n",
    "            \n",
    "        #Using topological order to infer probability\n",
    "        sampling_order = []\n",
    "        while len(sampling_order) < len(self.structure):\n",
    "            for i, deps in enumerate(self.structure):\n",
    "                if i in sampling_order:\n",
    "                    continue  # already ordered\n",
    "                if all(d in sampling_order for d in deps):\n",
    "                    sampling_order.append(i)\n",
    "        sampling_order = [self.node_names[i] for i in sampling_order]\n",
    "        print(sampling_order)\n",
    "\n",
    "        p_estimate = 1\n",
    "        for attr in sampling_order:\n",
    "            if attr in query:\n",
    "                print(attr)\n",
    "                val = query.pop(attr)\n",
    "                p = self.infer_machine.query([attr], evidence=query).values[val]*n_distinct[attr]\n",
    "                if np.isnan(p):\n",
    "                    p_estimate = 0\n",
    "                    break\n",
    "                p_estimate *= p\n",
    "                \n",
    "        if return_prob:\n",
    "            return (p_estimate, nrows)\n",
    "        return round(p_estimate * nrows)\n",
    "\n",
    "\n",
    "    def infer_point_query(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Variable elimination, which is the exact inference algorithm.\n",
    "            For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:x, Y:y, Z:z}\n",
    "                     x,y,z can only be a single value\n",
    "                     num_samples: only useful if using an approaximate inference\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "        \"\"\"\n",
    "        assert self.infer_algo is not None, \"must call .init_inference_method() first\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = toy_data_highly_correlated_cat(nrows=100000, return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model spec[('cont_attr3', 'cont_attr2'), ('cont_attr1', 'cont_attr3'), ('cont_attr8', 'cont_attr4'), ('cont_attr8', 'cont_attr5'), ('cont_attr3', 'cont_attr6'), ('cont_attr1', 'cont_attr7'), ('cont_attr3', 'cont_attr8')]\n",
      "calling pgm.BayesianModel.fit...\n",
      "done, took 0.09728121757507324 secs.\n"
     ]
    }
   ],
   "source": [
    "BN = Pgmpy_BN('title')\n",
    "BN.build_from_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 5628.68it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 324.38it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 5877.90it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 7/7 [00:00<00:00, 328.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n",
      "0.011144876480102539\n",
      "cont_attr1\n",
      "cont_attr2\n",
      "cont_attr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 4522.16it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 309.04it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 6763.45it/s]\n",
      "Eliminating: cont_attr6: 100%|██████████| 7/7 [00:00<00:00, 191.53it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 7210.84it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 293.13it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 6403.52it/s]\n",
      "Eliminating: cont_attr6: 100%|██████████| 7/7 [00:00<00:00, 211.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_attr1\n",
      "cont_attr2\n",
      "cont_attr1\n",
      "cont_attr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 6610.41it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 310.43it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 6499.92it/s]\n",
      "Eliminating: cont_attr6: 100%|██████████| 7/7 [00:00<00:00, 214.77it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 5515.19it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 314.86it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 5552.22it/s]\n",
      "Eliminating: cont_attr6:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_attr1\n",
      "cont_attr2\n",
      "cont_attr1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: cont_attr6: 100%|██████████| 7/7 [00:00<00:00, 209.34it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 5000.16it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 307.19it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 5631.02it/s]\n",
      "Eliminating: cont_attr6: 100%|██████████| 7/7 [00:00<00:00, 210.63it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 6818.16it/s]\n",
      "Eliminating: cont_attr8:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_attr2\n",
      "cont_attr1\n",
      "cont_attr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 324.80it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 5743.37it/s]\n",
      "Eliminating: cont_attr6: 100%|██████████| 7/7 [00:00<00:00, 196.88it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 6934.64it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 264.75it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 5604.15it/s]\n",
      "Eliminating: cont_attr8:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_attr1\n",
      "cont_attr1\n",
      "cont_attr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: cont_attr3: 100%|██████████| 7/7 [00:00<00:00, 271.60it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 4889.42it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 297.32it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 6603.72it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 7/7 [00:00<00:00, 312.58it/s]\n",
      "Finding Elimination Order: : 100%|██████████| 6/6 [00:00<00:00, 4619.28it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 6/6 [00:00<00:00, 317.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont_attr1\n",
      "cont_attr2\n",
      "cont_attr1\n",
      "cont_attr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 7/7 [00:00<00:00, 6381.25it/s]\n",
      "Eliminating: cont_attr3: 100%|██████████| 7/7 [00:00<00:00, 305.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034.0\n",
      "1.544321060180664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(len(df.query('cont_attr1 == 2').query('cont_attr2 == 3')))\n",
    "toc = time.time()\n",
    "print(toc-tic)\n",
    "BN.init_inference_method()\n",
    "print(BN.infer_point_query_BP({'cont_attr1': 2, 'cont_attr2': 3}, num_samples=1))\n",
    "print(time.time()-toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "inference = VariableElimination(BN.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a8a902130dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cont_attr1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cont_attr3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cont_attr4'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/pgmpy-0.1.10.dev0-py3.7.egg/pgmpy/inference/ExactInference.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, variables, evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0melimination_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melimination_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mjoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         )\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/pgmpy-0.1.10.dev0-py3.7.egg/pgmpy/inference/ExactInference.py\u001b[0m in \u001b[0;36m_variable_elimination\u001b[0;34m(self, variables, operation, evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0meliminated_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Get working factors and elimination order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mworking_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_working_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         elimination_order = self._get_elimination_order(\n\u001b[1;32m    161\u001b[0m             \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melimination_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/pgmpy-0.1.10.dev0-py3.7.egg/pgmpy/inference/ExactInference.py\u001b[0m in \u001b[0;36m_get_working_factors\u001b[0;34m(self, evidence)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworking_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevidence_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     factor_reduced = factor.reduce(\n\u001b[0;32m---> 46\u001b[0;31m                         \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevidence_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevidence_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                     )\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactor_reduced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/pgmpy-0.1.10.dev0-py3.7.egg/pgmpy/factors/discrete/DiscreteFactor.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, values, inplace)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             values = [\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_no\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             ]\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/pgmpy-0.1.10.dev0-py3.7.egg/pgmpy/factors/discrete/DiscreteFactor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             values = [\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_no\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             ]\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bayesnet/lib/python3.7/site-packages/pgmpy-0.1.10.dev0-py3.7.egg/pgmpy/utils/state_name.py\u001b[0m in \u001b[0;36mget_state_no\u001b[0;34m(self, var, state_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_to_no\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(inference.query(['cont_attr1'], evidence={'cont_attr3': [0,1], 'cont_attr4': [0,1]}))\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|██████████| 4/4 [00:00<00:00, 3370.27it/s]\n",
      "Eliminating: cont_attr8: 100%|██████████| 4/4 [00:00<00:00, 339.67it/s]\n"
     ]
    }
   ],
   "source": [
    "a = inference.query(['cont_attr1'], evidence={'cont_attr3': [0,1], 'cont_attr4': [0,1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.inference import BeliefPropagation\n",
    "infer_machine = BeliefPropagation(BN.model)\n",
    "infer_machine.calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: cont_attr8: 100%|██████████| 3/3 [00:00<00:00, 303.98it/s]\n"
     ]
    }
   ],
   "source": [
    "a = infer_machine.query(['cont_attr1'], evidence={'cont_attr2':1, 'cont_attr4':18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "| cont_attr1    |   phi(cont_attr1) |\n",
      "+===============+===================+\n",
      "| cont_attr1(0) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(1) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(2) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(3) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(4) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(5) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(6) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(7) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(8) |               nan |\n",
      "+---------------+-------------------+\n",
      "| cont_attr1(9) |               nan |\n",
      "+---------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(a.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(99.765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
