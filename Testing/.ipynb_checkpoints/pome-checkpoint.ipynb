{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections\n",
    "import time\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/ziniuwu/Desktop/research/BayesNet/Testing', '/Users/ziniuwu/anaconda3/envs/BayesNet/lib/python37.zip', '/Users/ziniuwu/anaconda3/envs/BayesNet/lib/python3.7', '/Users/ziniuwu/anaconda3/envs/BayesNet/lib/python3.7/lib-dynload', '', '/Users/ziniuwu/anaconda3/envs/BayesNet/lib/python3.7/site-packages', '/Users/ziniuwu/anaconda3/envs/BayesNet/lib/python3.7/site-packages/IPython/extensions', '/Users/ziniuwu/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ziniuwu/Desktop/research/BayesNet')\n",
    "from  import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_BN():\n",
    "    \"\"\"\n",
    "    Build a single Bayesian Network for a single table.\n",
    "    Initialize with an appropriate table_name.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, table_name, method='Pome'):\n",
    "        self.table_name = table_name\n",
    "        self.n_in_bin = dict()\n",
    "        self.encoding = dict()\n",
    "        self.mapping = dict()\n",
    "        self.max_value = dict()\n",
    "        self.model = None\n",
    "        self.method = method\n",
    "        \n",
    "        \n",
    "    def build_discrete_table(self, data, n_mcv, n_bins, drop_na=True, ignore_cols = []):\n",
    "        \"\"\"\n",
    "        Discretize the entire table use bining (This is using histogram method for continuous data)\n",
    "        ::Param:: table: original table\n",
    "                  n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                  n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "                  drop_na: if True, we drop all rows with nan in it\n",
    "                  ignore_cols: drop the unnessary columns for example id attribute\n",
    "        \"\"\"\n",
    "        table = data.copy()\n",
    "        if drop_na:\n",
    "            table = table.dropna()\n",
    "        for col in table.columns:\n",
    "            if col in ignore_cols:\n",
    "                table = table.drop(col, axis=1)\n",
    "            else:\n",
    "                table[col], self.n_in_bin[col], self.encoding[col], self.mapping[col] = tools.discretize_series(\n",
    "                    table[col],\n",
    "                    n_mcv=n_mcv,\n",
    "                    n_bins=n_bins,\n",
    "                    drop_na= not drop_na\n",
    "                )\n",
    "                self.max_value[col] = int(table[col].max())+1\n",
    "        self.node_names = list(table.columns)\n",
    "        return table\n",
    "\n",
    "    \n",
    "    def apply_encoding_to_value(self, value, col):\n",
    "        #return the encoded value given real value\n",
    "        if col not in self.encoding:\n",
    "            return value\n",
    "        elif value not in self.encoding[col]:\n",
    "            return value\n",
    "        return self.encoding[col][value]\n",
    "    \n",
    "    \n",
    "    def apply_ndistinct_to_value(self, enc_value, value, col):\n",
    "        #return the number of distinct value in the bin\n",
    "        if col not in self.n_in_bin:\n",
    "            return 1\n",
    "        elif enc_value not in self.n_in_bin[col]:\n",
    "            return 1\n",
    "        elif type(self.n_in_bin[col][enc_value])==int:\n",
    "            return 1/self.n_in_bin[col][enc_value]\n",
    "        elif value not in self.n_in_bin[col][enc_value]:\n",
    "            return 1\n",
    "        else:\n",
    "            return self.n_in_bin[col][enc_value][value]\n",
    "    \n",
    "    def build_from_data(self, dataset, n_mcv=30, n_bins=60, ignore_cols=['id'], algorithm=\"greedy\",\n",
    "                        drop_na=True, max_parents=-1, root=None, n_jobs=8):\n",
    "        \"\"\" Build the Pomegranate model from data, including structure learning and paramter learning\n",
    "            ::Param:: dataset: pandas.dataframe\n",
    "                      n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                      n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "            for other parameters, pomegranate gives a detailed explaination:\n",
    "            https://pomegranate.readthedocs.io/en/latest/BayesianNetwork.html\n",
    "        \"\"\"\n",
    "        self.nrows = len(dataset)\n",
    "        self.algorithm = algorithm\n",
    "        self.max_parents = max_parents\n",
    "        self.n_mcv = n_mcv\n",
    "        self.n_bins = n_bins\n",
    "        self.root = root\n",
    "        \n",
    "        discrete_table = self.build_discrete_table(dataset, n_mcv, n_bins, drop_na, ignore_cols)\n",
    "        print(f'building pomegranate.BayesianNetwork from data with {self.nrows} rows')\n",
    "        t = time.time()\n",
    "        self.model = pomegranate.BayesianNetwork.from_samples(discrete_table,\n",
    "                                                  algorithm=algorithm,\n",
    "                                                  state_names=self.node_names,\n",
    "                                                  max_parents=max_parents,\n",
    "                                                  n_jobs=8,\n",
    "                                                  root = self.root)\n",
    "        print(f'Took {time.time() - t} secs.')\n",
    "        \n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"bn{self.table_name}.{self.algorithm}-{self.max_parents}-{self.root}-{self.n_mcv}-{self.n_bins}\"\n",
    "    \n",
    "    \n",
    "    def load(self, path, pgm_path=None):\n",
    "        with open(path, 'r') as myfile:\n",
    "            json_model = myfile.read()\n",
    "        self.model = BayesianNetwork.from_json(json_model)\n",
    "            \n",
    "            \n",
    "    def save(self, path, pgm_path=None):\n",
    "        with open(path, 'w') as outfile:\n",
    "            outfile.write(self.model.to_json())\n",
    "            \n",
    "    \n",
    "    def loopy_belief_propagation(self, evidence, n_distinct):\n",
    "        \"\"\"Performance a LBP in random order.\n",
    "           This adapts the LBP implemented in pomegranate package itself.\n",
    "        \"\"\"\n",
    "        index = list(range(len(self.node_names)))\n",
    "        p_estimate = 1\n",
    "        \n",
    "        while len(index)!=0:\n",
    "            i = random.choice(index)\n",
    "            val = evidence[i]\n",
    "            if val is not None:\n",
    "                evidence[i] = None\n",
    "                dist = self.model.predict_proba(evidence)\n",
    "                p = dist[i].parameters[0][val]*n_distinct[i]\n",
    "                p_estimate *= p\n",
    "            index.remove(i)\n",
    "        return p_estimate\n",
    "        \n",
    "            \n",
    "    def infer_point_query_LBP(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Loopy belief propagation. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:x, Y:y, Z:z}\n",
    "                     x,y,z can only be a single value\n",
    "                     num_samples: how many times to run inference. Since Loopy belief propagation is sometime\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "        \"\"\"\n",
    "        ncols = len(query)\n",
    "        nrows = self.nrows\n",
    "                    \n",
    "        evidence = [None]*len(self.node_names)\n",
    "        n_distinct = [1]*len(self.node_names)\n",
    "        for attr in query:\n",
    "            ind = self.node_names.index(attr)\n",
    "            evidence[ind] = self.apply_encoding_to_value(query[attr], attr)\n",
    "            n_distinct[ind] = self.apply_ndistinct_to_value(evidence[ind], query[attr], attr)\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            #Using topological order to infer probability\n",
    "            sampling_order = []\n",
    "            while len(sampling_order) < len(self.model.structure):\n",
    "                for i, deps in enumerate(self.model.structure):\n",
    "                    if i in sampling_order:\n",
    "                        continue  # already ordered\n",
    "                    if all(d in sampling_order for d in deps):\n",
    "                        sampling_order.append(i)\n",
    "            \n",
    "            p_estimate = 1\n",
    "            for i in sampling_order:\n",
    "                val = evidence[i]\n",
    "                if val is not None:\n",
    "                    evidence[i] = None\n",
    "                    dist = self.model.predict_proba(evidence)\n",
    "                    p = dist[i].parameters[0][val]*n_distinct[i]\n",
    "                    p_estimate *= p\n",
    "                        \n",
    "        else:\n",
    "            p_estimates = []\n",
    "            for i in range(num_samples):\n",
    "                copy_evidence = copy.deepcopy(evidence)\n",
    "                p_estimates.append(self.loopy_belief_propagation(copy_evidence, n_distinct))\n",
    "            p_estimate = sum(p_estimates)/num_samples\n",
    "        \n",
    "        if return_prob:\n",
    "            return (p_estimate, nrows)\n",
    "        return int(p_estimate * nrows)\n",
    "    \n",
    "    \n",
    "    def infer_range_query_LBP(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Loopy belief propagation. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:[x], Y:[y], Z:[z]}\n",
    "                     x,y,z can only be set of single value\n",
    "                     num_samples: how many times to run inference. Since Loopy belief propagation is sometime\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "           LBP for estimating range query can be really slow\n",
    "        \"\"\"\n",
    "        def cartesian_product(d):\n",
    "            target_list = []\n",
    "            for key in d:\n",
    "                val = d[key]\n",
    "                if type(val) != list:\n",
    "                    val = [val]\n",
    "                target_list.append(val)\n",
    "            return itertools.product(*target_list)\n",
    "        \n",
    "        \n",
    "        p_estimate = 0\n",
    "        for query_tuple in cartesian_product(query):\n",
    "            point_query = dict()\n",
    "            i = 0\n",
    "            for attr in query:\n",
    "                point_query[attr] = query_tuple[i]\n",
    "                i += 1\n",
    "            p_estimate += self.infer_point_query_LBP(point_query, return_prob=True)[0]\n",
    "        \n",
    "        return p_estimate*self.nrows\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table_csv(n = 20):\n",
    "    \"\"\"\n",
    "    Reads csv from path\n",
    "    n: every nth line = 1% of the lines\n",
    "    \"\"\"\n",
    "    filename = \"/Users/ziniuwu/Desktop/research/imdb/title.csv\"\n",
    "    df = pd.read_csv(filename, header=0, escapechar='\\\\', encoding='utf-8', quotechar='\"',\n",
    "                          sep=',', skiprows=lambda i: i % n != 0)\n",
    "    df.columns=['id', 'title', 'imdb_index', 'kind_id', 'production_year', 'imdb_id',\n",
    "                                                'phonetic_code', 'episode_of_id', 'season_nr', 'episode_nr',\n",
    "                                                'series_years', 'md5sum']\n",
    "    for name in ['episode_of_id', 'title', 'imdb_index', 'phonetic_code', 'season_nr',\n",
    "                                                  'imdb_id', 'episode_nr', 'series_years', 'md5sum']:\n",
    "        df = df.drop(name, axis=1)\n",
    "    df['random1'] = np.random.randint(10, size=len(df))\n",
    "    df['random2'] = np.random.randint(3, size=len(df))+10\n",
    "    df['random3'] = np.random.normal(3, 100, size=len(df))\n",
    "    return df.apply(pd.to_numeric, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12639\n"
     ]
    }
   ],
   "source": [
    "df = read_table_csv(200)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building pomegranate.BayesianNetwork from data with 12639 rows\n",
      "Took 0.27854204177856445 secs.\n"
     ]
    }
   ],
   "source": [
    "BN = Single_BN('title')\n",
    "BN.build_from_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(evidence, BN):\n",
    "    pred = BN.model.predict_proba([None, None, None, None, None])\n",
    "    p = 1\n",
    "    for (col, v) in evidence:\n",
    "        i = BN.node_names.index(col)\n",
    "        print(pred[i].parameters[0][BN.encoding[col][v]])\n",
    "        p*=pred[i].parameters[0][BN.encoding[col][v]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.query('production_year in [2011,2012]').query('random1 == 2').query('random2 == [10,11]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BN.infer_range_query_LBP({'production_year': [2011,2012], 'random1':2, 'random2':[10,11]}, num_samples=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN.model.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "somelists = [\n",
    "   [1, 2, 3],\n",
    "   ['a', 'b'],\n",
    "   [4, 5]\n",
    "]\n",
    "for element in itertools.product(*somelists):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.Inf > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.Inf > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
