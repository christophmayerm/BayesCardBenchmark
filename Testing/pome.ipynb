{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections\n",
    "import time\n",
    "import math\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ziniuwu/Desktop/research/BayesNet')\n",
    "from Structure.tools import discretize_series\n",
    "from Testing.toy_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_BN():\n",
    "    \"\"\"\n",
    "    Build a single Bayesian Network for a single table.\n",
    "    Initialize with an appropriate table_name.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, table_name, method='Pome'):\n",
    "        self.table_name = table_name\n",
    "        self.n_in_bin = dict()\n",
    "        self.encoding = dict()\n",
    "        self.mapping = dict()\n",
    "        self.max_value = dict()\n",
    "        self.model = None\n",
    "        self.method = method\n",
    "        \n",
    "        \n",
    "    def build_discrete_table(self, data, n_mcv, n_bins, drop_na=True, ignore_cols = []):\n",
    "        \"\"\"\n",
    "        Discretize the entire table use bining (This is using histogram method for continuous data)\n",
    "        ::Param:: table: original table\n",
    "                  n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                  n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "                  drop_na: if True, we drop all rows with nan in it\n",
    "                  ignore_cols: drop the unnessary columns for example id attribute\n",
    "        \"\"\"\n",
    "        table = data.copy()\n",
    "        if drop_na:\n",
    "            table = table.dropna()\n",
    "        for col in table.columns:\n",
    "            if col in ignore_cols:\n",
    "                table = table.drop(col, axis=1)\n",
    "            else:\n",
    "                table[col], self.n_in_bin[col], self.encoding[col], self.mapping[col] = discretize_series(\n",
    "                    table[col],\n",
    "                    n_mcv=n_mcv,\n",
    "                    n_bins=n_bins,\n",
    "                    drop_na= not drop_na\n",
    "                )\n",
    "                self.max_value[col] = int(table[col].max())+1\n",
    "        self.node_names = list(table.columns)\n",
    "        return table\n",
    "\n",
    "    \n",
    "    def apply_encoding_to_value(self, value, col):\n",
    "        #return the encoded value given real value\n",
    "        if col not in self.encoding:\n",
    "            return value\n",
    "        elif value not in self.encoding[col]:\n",
    "            return value\n",
    "        return self.encoding[col][value]\n",
    "    \n",
    "    \n",
    "    def apply_ndistinct_to_value(self, enc_value, value, col):\n",
    "        #return the number of distinct value in the bin\n",
    "        if col not in self.n_in_bin:\n",
    "            return 1\n",
    "        elif enc_value not in self.n_in_bin[col]:\n",
    "            return 1\n",
    "        elif type(self.n_in_bin[col][enc_value])==int:\n",
    "            return 1/self.n_in_bin[col][enc_value]\n",
    "        elif value not in self.n_in_bin[col][enc_value]:\n",
    "            return 1\n",
    "        else:\n",
    "            return self.n_in_bin[col][enc_value][value]\n",
    "    \n",
    "    def build_from_data(self, dataset, n_mcv=30, n_bins=60, ignore_cols=['id'], algorithm=\"greedy\",\n",
    "                        drop_na=True, max_parents=-1, root=0, n_jobs=8):\n",
    "        \"\"\" Build the Pomegranate model from data, including structure learning and paramter learning\n",
    "            ::Param:: dataset: pandas.dataframe\n",
    "                      n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                      n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "            for other parameters, pomegranate gives a detailed explaination:\n",
    "            https://pomegranate.readthedocs.io/en/latest/BayesianNetwork.html\n",
    "        \"\"\"\n",
    "        self.nrows = len(dataset)\n",
    "        self.algorithm = algorithm\n",
    "        self.max_parents = max_parents\n",
    "        self.n_mcv = n_mcv\n",
    "        self.n_bins = n_bins\n",
    "        self.root = root\n",
    "        \n",
    "        discrete_table = self.build_discrete_table(dataset, n_mcv, n_bins, drop_na, ignore_cols)\n",
    "        print(f'building pomegranate.BayesianNetwork from data with {self.nrows} rows')\n",
    "        t = time.time()\n",
    "        self.model = pomegranate.BayesianNetwork.from_samples(discrete_table,\n",
    "                                                  algorithm=algorithm,\n",
    "                                                  state_names=self.node_names,\n",
    "                                                  max_parents=max_parents,\n",
    "                                                  n_jobs=8,\n",
    "                                                  root = self.root)\n",
    "        print(f'Took {time.time() - t} secs.')\n",
    "        \n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"bn{self.table_name}.{self.algorithm}-{self.max_parents}-{self.root}-{self.n_mcv}-{self.n_bins}\"\n",
    "    \n",
    "    \n",
    "    def load(self, path, pgm_path=None):\n",
    "        with open(path, 'r') as myfile:\n",
    "            json_model = myfile.read()\n",
    "        self.model = BayesianNetwork.from_json(json_model)\n",
    "            \n",
    "            \n",
    "    def save(self, path, pgm_path=None):\n",
    "        with open(path, 'w') as outfile:\n",
    "            outfile.write(self.model.to_json())\n",
    "            \n",
    "    \n",
    "    def loopy_belief_propagation(self, evidence, n_distinct):\n",
    "        \"\"\"Performance a LBP in random order.\n",
    "           This adapts the LBP implemented in pomegranate package itself.\n",
    "        \"\"\"\n",
    "        index = list(range(len(self.node_names)))\n",
    "        p_estimate = 1\n",
    "        \n",
    "        while len(index)!=0:\n",
    "            i = random.choice(index)\n",
    "            val = evidence[i]\n",
    "            if val is not None:\n",
    "                evidence[i] = None\n",
    "                dist = self.model.predict_proba(evidence)\n",
    "                p = dist[i].parameters[0][val]*n_distinct[i]\n",
    "                p_estimate *= p\n",
    "            index.remove(i)\n",
    "        return p_estimate\n",
    "        \n",
    "            \n",
    "    def infer_point_query_LBP(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Loopy belief propagation. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:x, Y:y, Z:z}\n",
    "                     x,y,z can only be a single value\n",
    "                     num_samples: how many times to run inference. Since Loopy belief propagation is sometime\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "        \"\"\"\n",
    "        ncols = len(query)\n",
    "        nrows = self.nrows\n",
    "                    \n",
    "        evidence = [None]*len(self.node_names)\n",
    "        n_distinct = [1]*len(self.node_names)\n",
    "        for attr in query:\n",
    "            ind = self.node_names.index(attr)\n",
    "            evidence[ind] = self.apply_encoding_to_value(query[attr], attr)\n",
    "            n_distinct[ind] = self.apply_ndistinct_to_value(evidence[ind], query[attr], attr)\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            #Using topological order to infer probability\n",
    "            sampling_order = []\n",
    "            while len(sampling_order) < len(self.model.structure):\n",
    "                for i, deps in enumerate(self.model.structure):\n",
    "                    if i in sampling_order:\n",
    "                        continue  # already ordered\n",
    "                    if all(d in sampling_order for d in deps):\n",
    "                        sampling_order.append(i)\n",
    "            \n",
    "            p_estimate = 1\n",
    "            for i in sampling_order:\n",
    "                val = evidence[i]\n",
    "                if val is not None:\n",
    "                    evidence[i] = None\n",
    "                    dist = self.model.predict_proba(evidence)\n",
    "                    p = dist[i].parameters[0][val]*n_distinct[i]\n",
    "                    p_estimate *= p\n",
    "                        \n",
    "        else:\n",
    "            p_estimates = []\n",
    "            for i in range(num_samples):\n",
    "                copy_evidence = copy.deepcopy(evidence)\n",
    "                p_estimates.append(self.loopy_belief_propagation(copy_evidence, n_distinct))\n",
    "            p_estimate = sum(p_estimates)/num_samples\n",
    "        \n",
    "        if return_prob:\n",
    "            return (p_estimate, nrows)\n",
    "        return int(p_estimate * nrows)\n",
    "    \n",
    "    \n",
    "    def infer_range_query_LBP(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using Loopy belief propagation. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:[x], Y:[y], Z:[z]}\n",
    "                     x,y,z can only be set of single value\n",
    "                     num_samples: how many times to run inference. Since Loopy belief propagation is sometime\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "           LBP for estimating range query can be really slow\n",
    "        \"\"\"\n",
    "        def cartesian_product(d):\n",
    "            target_list = []\n",
    "            for key in d:\n",
    "                val = d[key]\n",
    "                if type(val) != list:\n",
    "                    val = [val]\n",
    "                target_list.append(val)\n",
    "            return itertools.product(*target_list)\n",
    "        \n",
    "        \n",
    "        p_estimate = 0\n",
    "        for query_tuple in cartesian_product(query):\n",
    "            point_query = dict()\n",
    "            i = 0\n",
    "            for attr in query:\n",
    "                point_query[attr] = query_tuple[i]\n",
    "                i += 1\n",
    "            p_estimate += self.infer_point_query_LBP(point_query, return_prob=True)[0]\n",
    "        \n",
    "        return p_estimate*self.nrows\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont_attr1</th>\n",
       "      <th>cont_attr2</th>\n",
       "      <th>cont_attr3</th>\n",
       "      <th>cont_attr4</th>\n",
       "      <th>cont_attr5</th>\n",
       "      <th>cont_attr6</th>\n",
       "      <th>cont_attr7</th>\n",
       "      <th>cont_attr8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  cont_attr1  cont_attr2  cont_attr3  cont_attr4  cont_attr5  \\\n",
       "0    0           5           5          10          10          20   \n",
       "1    1           0           0           0           0           0   \n",
       "2    2           3           3           6           6          12   \n",
       "3    3           3           4           7           9          16   \n",
       "4    4           7           7          14          14          28   \n",
       "5    5           9           9          18          18          36   \n",
       "6    6           3           4           7           7          14   \n",
       "7    7           5           5          10          10          20   \n",
       "8    8           2           2           4           4           8   \n",
       "9    9           4           4           8           8          16   \n",
       "10  10           7           7          14          14          28   \n",
       "11  11           6           6          12          12          24   \n",
       "12  12           8           8          16          16          32   \n",
       "13  13           8           8          16          16          32   \n",
       "14  14           1           1           2           2           4   \n",
       "15  15           6           6          12          12          24   \n",
       "16  16           7           7          14          14          28   \n",
       "17  17           7           7          14          14          28   \n",
       "18  18           8           8          16          18          34   \n",
       "19  19           1           2           3           5           8   \n",
       "\n",
       "    cont_attr6  cont_attr7  cont_attr8  \n",
       "0           15          15          50  \n",
       "1            0          10          10  \n",
       "2            8          13          34  \n",
       "3           15          13          41  \n",
       "4           17          17          66  \n",
       "5           22          19          82  \n",
       "6           17          13          37  \n",
       "7           14          15          50  \n",
       "8           11          12          26  \n",
       "9           17          14          42  \n",
       "10          21          17          66  \n",
       "11          17          16          58  \n",
       "12          23          18          74  \n",
       "13          18          18          74  \n",
       "14           4          11          18  \n",
       "15          18          16          58  \n",
       "16          23          17          66  \n",
       "17          15          17          66  \n",
       "18          22          18          78  \n",
       "19          12          11          25  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = toy_data_highly_correlated_cat(nrows=100000, return_df=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building pomegranate.BayesianNetwork from data with 100000 rows\n",
      "Took 1.4268620014190674 secs.\n"
     ]
    }
   ],
   "source": [
    "BN = Single_BN('title')\n",
    "BN.build_from_data(df, algorithm='chow-liu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), (2,), (0,), (7,), (7,), (2,), (0,), (2,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BN.model.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(evidence, BN):\n",
    "    pred = BN.model.predict_proba([None, None, None, None, None])\n",
    "    p = 1\n",
    "    for (col, v) in evidence:\n",
    "        i = BN.node_names.index(col)\n",
    "        print(pred[i].parameters[0][BN.encoding[col][v]])\n",
    "        p*=pred[i].parameters[0][BN.encoding[col][v]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8241\n",
      "0.02106332778930664\n",
      "8240.999999999889\n",
      "2.7123477458953857\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(len(df.query('cont_attr1 in [3,6,7]').query('cont_attr2 == 3').query('cont_attr4 == [6,7,14]')))\n",
    "toc = time.time()\n",
    "print(toc-tic)\n",
    "print(BN.infer_range_query_LBP({'cont_attr1': [3,6,7], 'cont_attr2': 3, 'cont_attr4': [6,7,14]}, num_samples=1))\n",
    "print(time.time()-toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.query('production_year in [2011,2012]').query('random1 == 2').query('random2 == [10,11]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BN.infer_range_query_LBP({'production_year': [2011,2012], 'random1':2, 'random2':[10,11]}, num_samples=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN.model.structure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
