{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import sys\n",
    "sys.path.append('/Users/ziniuwu/Desktop/research/BayesCard')\n",
    "from Pgmpy.factors import factor_product\n",
    "from Pgmpy.models import BayesianModel, JunctionTree\n",
    "from Pgmpy.inference.EliminationOrder import (\n",
    "    WeightedMinFill,\n",
    "    MinNeighbors,\n",
    "    MinFill,\n",
    "    MinWeight,\n",
    ")\n",
    "from Pgmpy.factors.discrete import TabularCPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import copy\n",
    "from Models.pgmpy_BN import Pgmpy_BN\n",
    "from Testing.toy_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableElimination(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        model.check_model()\n",
    "\n",
    "        if isinstance(model, JunctionTree):\n",
    "            self.variables = set(chain(*model.nodes()))\n",
    "        else:\n",
    "            self.variables = model.nodes()\n",
    "\n",
    "        self.cardinality = {}\n",
    "        self.factors = defaultdict(list)\n",
    "\n",
    "        if isinstance(model, BayesianModel):\n",
    "            self.state_names_map = {}\n",
    "            for node in model.nodes():\n",
    "                cpd = model.get_cpds(node)\n",
    "                if isinstance(cpd, TabularCPD):\n",
    "                    self.cardinality[node] = cpd.variable_card\n",
    "                    cpd = cpd.to_factor()\n",
    "                for var in cpd.scope():\n",
    "                    self.factors[var].append(cpd)\n",
    "                self.state_names_map.update(cpd.no_to_name)\n",
    "\n",
    "        elif isinstance(model, JunctionTree):\n",
    "            self.cardinality = model.get_cardinality()\n",
    "\n",
    "            for factor in model.get_factors():\n",
    "                for var in factor.variables:\n",
    "                    self.factors[var].append(factor)\n",
    "        self.root = self.get_root()\n",
    "\n",
    "        \n",
    "    def get_root(self):\n",
    "        \"\"\"Returns the network's root node.\"\"\"\n",
    "        def find_root(graph, node):\n",
    "            predecessor = next(self.model.predecessors(node), None)\n",
    "            if predecessor:\n",
    "                root = find_root(graph, predecessor)\n",
    "            else:\n",
    "                root = node\n",
    "            return root\n",
    "\n",
    "        return find_root(self, list(self.model.nodes)[0])\n",
    "    \n",
    "    \n",
    "    def steiner_tree(self, nodes):\n",
    "        \"\"\"Returns the minimal part of the tree that contains a set of nodes.\"\"\"\n",
    "        sub_nodes = set()\n",
    "\n",
    "        def walk(node, path):\n",
    "\n",
    "            if len(nodes) == 0:\n",
    "                return\n",
    "\n",
    "            if node in nodes:\n",
    "                sub_nodes.update(path + [node])\n",
    "                nodes.remove(node)\n",
    "\n",
    "            for child in self.model.successors(node):\n",
    "                walk(child, path + [node])\n",
    "        walk(self.root, [])\n",
    "        sub_graph = self.model.subgraph(sub_nodes)\n",
    "        sub_graph.cardinalities = defaultdict(int)\n",
    "        for node in sub_graph.nodes:\n",
    "            sub_graph.cardinalities[node] = self.model.cardinalities[node]\n",
    "        return sub_graph\n",
    "    \n",
    "    \n",
    "    def _get_working_factors(self, variables, evidence):\n",
    "        \"\"\"\n",
    "        Uses the evidence given to the query methods to modify the factors before running\n",
    "        the variable elimination algorithm.\n",
    "        Parameters\n",
    "        ----------\n",
    "        evidence: dict\n",
    "            Dict of the form {variable: state}\n",
    "        Returns\n",
    "        -------\n",
    "        dict: Modified working factors.\n",
    "        \"\"\"\n",
    "        useful_var = variables + list(evidence.keys())\n",
    "        sub_graph_model = self.steiner_tree(useful_var)\n",
    "        variables_sub_graph = set(sub_graph_model.nodes)\n",
    "        \n",
    "        working_factors = dict()\n",
    "        for node in sub_graph_model.nodes:\n",
    "            working_factors[node] = set()\n",
    "            for factor in self.factors[node]:\n",
    "                if set(factor.variables).issubset(variables_sub_graph):\n",
    "                    working_factors[node].add((factor, None))\n",
    "\n",
    "        # Dealing with evidence. Reducing factors over it before VE is run.\n",
    "        if evidence:\n",
    "            for evidence_var in evidence:\n",
    "                for factor, origin in working_factors[evidence_var]:\n",
    "                    factor_reduced = factor.reduce(\n",
    "                        [(evidence_var, evidence[evidence_var])], inplace=False\n",
    "                    )\n",
    "                    for var in factor_reduced.scope():\n",
    "                        if var in working_factors:\n",
    "                            working_factors[var].remove((factor, origin))\n",
    "                            working_factors[var].add((factor_reduced, evidence_var))\n",
    "                if type(evidence[evidence_var]) != list:\n",
    "                    del working_factors[evidence_var]\n",
    "        return working_factors, sub_graph_model\n",
    "    \n",
    "    def _get_elimination_order(\n",
    "        self, variables, evidence, model=None, elimination_order=\"minfill\", show_progress=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Deals with all elimination order parameters given to _variable_elimination method\n",
    "        and returns a list of variables that are to be eliminated\n",
    "        Parameters\n",
    "        ----------\n",
    "        elimination_order: str or list\n",
    "        Returns\n",
    "        -------\n",
    "        list: A list of variables names in the order they need to be eliminated.\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        if isinstance(model, JunctionTree):\n",
    "            all_variables = set(chain(*model.nodes()))\n",
    "        else:\n",
    "            all_variables = model.nodes()\n",
    "        \n",
    "        not_evidence_eliminate = []\n",
    "        if evidence is not None:\n",
    "            for key in evidence:\n",
    "                if type(evidence[key]) != list:\n",
    "                    not_evidence_eliminate.append(key)\n",
    "        to_eliminate = (\n",
    "            set(all_variables)\n",
    "            - set(variables)\n",
    "            - set(not_evidence_eliminate)\n",
    "        )\n",
    "\n",
    "        # Step 1: If elimination_order is a list, verify it's correct and return.\n",
    "        if hasattr(elimination_order, \"__iter__\") and (\n",
    "            not isinstance(elimination_order, str)\n",
    "        ):\n",
    "            if any(\n",
    "                var in elimination_order\n",
    "                for var in set(variables).union(\n",
    "                    set(evidence.keys() if evidence else [])\n",
    "                )\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Elimination order contains variables which are in\"\n",
    "                    \" variables or evidence args\"\n",
    "                )\n",
    "            else:\n",
    "                return elimination_order\n",
    "\n",
    "        # Step 2: If elimination order is None or a Markov model, return a random order.\n",
    "        elif (elimination_order is None) or (not isinstance(model, BayesianModel)):\n",
    "            return to_eliminate\n",
    "\n",
    "        # Step 3: If elimination order is a str, compute the order using the specified heuristic.\n",
    "        elif isinstance(elimination_order, str) and isinstance(\n",
    "            model, BayesianModel\n",
    "        ):\n",
    "            heuristic_dict = {\n",
    "                \"weightedminfill\": WeightedMinFill,\n",
    "                \"minneighbors\": MinNeighbors,\n",
    "                \"minweight\": MinWeight,\n",
    "                \"minfill\": MinFill,\n",
    "            }\n",
    "            elimination_order = heuristic_dict[elimination_order.lower()](\n",
    "                model\n",
    "            ).get_elimination_order(nodes=to_eliminate, show_progress=show_progress)\n",
    "            return elimination_order\n",
    "    \n",
    "    def _variable_elimination(\n",
    "        self,\n",
    "        variables,\n",
    "        operation,\n",
    "        evidence=None,\n",
    "        elimination_order=\"minfill\",\n",
    "        joint=True,\n",
    "        show_progress=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of a generalized variable elimination.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        variables: list, array-like\n",
    "            variables that are not to be eliminated.\n",
    "\n",
    "        operation: str ('marginalize' | 'maximize')\n",
    "            The operation to do for eliminating the variable.\n",
    "\n",
    "        evidence: dict\n",
    "            a dict key, value pair as {var: state_of_var_observed}\n",
    "            None if no evidence\n",
    "\n",
    "        elimination_order: str or list (array-like)\n",
    "            If str: Heuristic to use to find the elimination order.\n",
    "            If array-like: The elimination order to use.\n",
    "            If None: A random elimination order is used.\n",
    "        \"\"\"\n",
    "        # Step 1: Deal with the input arguments.\n",
    "        if isinstance(variables, str):\n",
    "            raise TypeError(\"variables must be a list of strings\")\n",
    "        if isinstance(evidence, str):\n",
    "            raise TypeError(\"evidence must be a list of strings\")\n",
    "\n",
    "        # Dealing with the case when variables is not provided.\n",
    "        if not variables:\n",
    "            all_factors = []\n",
    "            for factor_li in self.factors.values():\n",
    "                all_factors.extend(factor_li)\n",
    "            if joint:\n",
    "                return factor_product(*set(all_factors))\n",
    "            else:\n",
    "                return set(all_factors)\n",
    "\n",
    "        # Step 2: Prepare data structures to run the algorithm.\n",
    "        eliminated_variables = set()\n",
    "        # Get working factors and elimination order\n",
    "        tic = time.time()\n",
    "        working_factors, sub_graph_model = self._get_working_factors(variables, evidence)\n",
    "        toc = time.time()\n",
    "        print(f\"getting working factors takes {toc-tic} secs\")\n",
    "        elimination_order = self._get_elimination_order(\n",
    "            variables, evidence, sub_graph_model, elimination_order, show_progress=show_progress\n",
    "        )\n",
    "        print(f\"getting elimination orders takes {time.time()-toc} secs\")\n",
    "        # Step 3: Run variable elimination\n",
    "        if show_progress:\n",
    "            pbar = tqdm(elimination_order)\n",
    "        else:\n",
    "            pbar = elimination_order\n",
    "\n",
    "        for var in pbar:\n",
    "            tic = time.time()\n",
    "            print(var)\n",
    "            if show_progress:\n",
    "                pbar.set_description(\"Eliminating: {var}\".format(var=var))\n",
    "            # Removing all the factors containing the variables which are\n",
    "            # eliminated (as all the factors should be considered only once)\n",
    "            factors = [\n",
    "                factor\n",
    "                for factor, _ in working_factors[var]\n",
    "                if not set(factor.variables).intersection(eliminated_variables)\n",
    "            ]\n",
    "            if var == \"iYearwrk\":\n",
    "                print(factors)\n",
    "            phi = factor_product(*factors)\n",
    "            phi = getattr(phi, operation)([var], inplace=False)\n",
    "            del working_factors[var]\n",
    "            for variable in phi.variables:\n",
    "                if variable in working_factors:\n",
    "                    working_factors[variable].add((phi, var))\n",
    "            eliminated_variables.add(var)\n",
    "            print(f\"eliminating {var} takes {time.time()-tic} secs\")\n",
    "            \n",
    "        # Step 4: Prepare variables to be returned.\n",
    "        tic = time.time()\n",
    "        final_distribution = set()\n",
    "        for node in working_factors:\n",
    "            for factor, origin in working_factors[node]:\n",
    "                if not set(factor.variables).intersection(eliminated_variables):\n",
    "                    final_distribution.add((factor, origin))\n",
    "        final_distribution = [factor for factor, _ in final_distribution]\n",
    "        print(final_distribution)\n",
    "        print(f\"the rest takes {time.time()-tic} secs\")\n",
    "        if joint:\n",
    "            if isinstance(self.model, BayesianModel):\n",
    "                return factor_product(*final_distribution).normalize(inplace=False)\n",
    "            else:\n",
    "                return factor_product(*final_distribution)\n",
    "        else:\n",
    "            query_var_factor = {}\n",
    "            for query_var in variables:\n",
    "                phi = factor_product(*final_distribution)\n",
    "                query_var_factor[query_var] = phi.marginalize(\n",
    "                    list(set(variables) - set([query_var])), inplace=False\n",
    "                ).normalize(inplace=False)\n",
    "            print(f\"the rest takes {time.time()-tic} secs\")\n",
    "            return query_var_factor\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        variables,\n",
    "        evidence=None,\n",
    "        elimination_order=\"MinFill\",\n",
    "        joint=True,\n",
    "        show_progress=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        variables: list\n",
    "            list of variables for which you want to compute the probability\n",
    "\n",
    "        evidence: dict\n",
    "            a dict key, value pair as {var: state_of_var_observed}\n",
    "            None if no evidence\n",
    "\n",
    "        elimination_order: list\n",
    "            order of variable eliminations (if nothing is provided) order is\n",
    "            computed automatically\n",
    "\n",
    "        joint: boolean (default: True)\n",
    "            If True, returns a Joint Distribution over `variables`.\n",
    "            If False, returns a dict of distributions over each of the `variables`.\n",
    "        \"\"\"\n",
    "        common_vars = set(evidence if evidence is not None else []).intersection(\n",
    "            set(variables)\n",
    "        )\n",
    "        if common_vars:\n",
    "            raise ValueError(\n",
    "                f\"Can't have the same variables in both `variables` and `evidence`. Found in both: {common_vars}\"\n",
    "            )\n",
    "\n",
    "        return self._variable_elimination(\n",
    "            variables=variables,\n",
    "            operation=\"marginalize\",\n",
    "            evidence=evidence,\n",
    "            elimination_order=elimination_order,\n",
    "            joint=joint,\n",
    "            show_progress=show_progress,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('check_points/Census_chow-liu.pkl', 'rb') as f:\n",
    "    BN = pickle.load(f)\n",
    "with open('check_points/Census_junction.pkl', 'rb') as f:\n",
    "    BN_J = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN.model.cardinalities = BN.model.get_cardinality()\n",
    "ve = VariableElimination(BN.model)\n",
    "factors = ve.factors\n",
    "cpds = BN.model.cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Internal error in pre-inference rewriting pass encountered during compilation of function \"reduce\" due to: Constant inference not possible for: call $42load_global.2($48binary_subscr.5, func=$42load_global.2, args=[Var($48binary_subscr.5, DiscreteFactor.py:306)], kws=(), vararg=None)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 306:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "            raise TypeError(\n",
      "                \"values: Expected type list of tuples, get type {type}\", type(values[0])\n",
      "                ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: Untyped global name 'isinstance': cannot determine Numba type of <class 'builtin_function_or_method'>\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (318)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (330)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Internal error in pre-inference rewriting pass encountered during compilation of function \"reduce\" due to: Constant inference not possible for: call $42load_global.2($48binary_subscr.5, func=$42load_global.2, args=[Var($48binary_subscr.5, DiscreteFactor.py:306)], kws=(), vararg=None)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 306:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "            raise TypeError(\n",
      "                \"values: Expected type list of tuples, get type {type}\", type(values[0])\n",
      "                ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: Untyped global name 'isinstance': cannot determine Numba type of <class 'builtin_function_or_method'>\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 301:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # Check if values is an array\n",
      "        if isinstance(values, str):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (318)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  @jit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 318:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        # state numbers.\n",
      "        for i, (var, state_name) in enumerate(values):\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py:281: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"reduce\" failed type inference due to: non-precise type pyobject\n",
      "During: typing of argument at /Users/ziniuwu/Desktop/research/BayesCard/Pgmpy/factors/discrete/DiscreteFactor.py (330)\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  @jit\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:178: NumbaWarning: Function \"reduce\" was compiled in object mode without forceobj=True.\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/Users/ziniuwu/anaconda3/envs/bayesnet/lib/python3.7/site-packages/numba/core/object_mode_passes.py:188: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit https://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../Pgmpy/factors/discrete/DiscreteFactor.py\", line 330:\n",
      "    def reduce(self, values, inplace=True):\n",
      "        <source elided>\n",
      "        del_state_names = []\n",
      "        for var, state in values:\n",
      "        ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "f, s =ve._get_working_factors([\"iAvail\"], {\"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f.keys())\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting working factors takes 0.06838679313659668 secs\n",
      "getting elimination orders takes 0.0014400482177734375 secs\n",
      "iLooking\n",
      "eliminating iLooking takes 0.0014781951904296875 secs\n",
      "iKorean\n",
      "eliminating iKorean takes 0.0003991127014160156 secs\n",
      "iRagechld\n",
      "eliminating iRagechld takes 0.00036787986755371094 secs\n",
      "iRlabor\n",
      "eliminating iRlabor takes 0.0066530704498291016 secs\n",
      "iRspouse\n",
      "eliminating iRspouse takes 0.002586841583251953 secs\n",
      "iMilitary\n",
      "eliminating iMilitary takes 0.012909889221191406 secs\n",
      "iFertil\n",
      "eliminating iFertil takes 0.0006821155548095703 secs\n",
      "dAge\n",
      "eliminating dAge takes 0.0028450489044189453 secs\n",
      "iRvetserv\n",
      "eliminating iRvetserv takes 0.0013859272003173828 secs\n",
      "dIndustry\n",
      "eliminating dIndustry takes 0.0004630088806152344 secs\n",
      "dOccup\n",
      "eliminating dOccup takes 0.00048422813415527344 secs\n",
      "iYearwrk\n",
      "[<DiscreteFactor representing phi(iRelat1:14, iYearwrk:8) at 0x1a327aa990>, <DiscreteFactor representing phi(iYearwrk:8) at 0x1a327aa6d0>, <DiscreteFactor representing phi(iAvail:5, iYearwrk:8) at 0x1a33515e50>]\n",
      "eliminating iYearwrk takes 0.0017390251159667969 secs\n",
      "iRelat1\n",
      "eliminating iRelat1 takes 0.0007922649383544922 secs\n",
      "[<DiscreteFactor representing phi(iAvail:5) at 0x1a327aa850>]\n",
      "the rest takes 0.00028896331787109375 secs\n",
      "0.10466480255126953\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "q = ve.query([\"iAvail\"], {\"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0},\n",
    "            elimination_order=\"weightedminfill\")\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ve = VariableElimination(BN.model)\n",
    "BN.infer_machine = ve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(BN, open('check_points/Census_chow-liu.pkl', 'wb'), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BN.query({\"iAvail\": 0, \"iClass\": 0, \"iKorean\": [0,1], \"iMay75880\": 0, \"iRagechld\": [0, 4], \"iRrelchld\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.cardinality_estimation import parse_query_single_table\n",
    "from time import perf_counter\n",
    "def evaluate_cardinality(BN, query_path):\n",
    "    # read all queries\n",
    "    with open(query_path) as f:\n",
    "        queries = f.readlines()\n",
    "    latencies = []\n",
    "    q_errors = []\n",
    "    for query_no, query_str in enumerate(queries):\n",
    "        cardinality_true = int(query_str.split(\"||\")[-1])\n",
    "        query_str = query_str.split(\"||\")[0]\n",
    "        print(f\"Predicting cardinality for query {query_no}: {query_str}\")\n",
    "        \n",
    "        query = parse_query_single_table(query_str.strip(), BN)\n",
    "        card_start_t = perf_counter()\n",
    "        print(query)\n",
    "        try:\n",
    "            cardinality_predict = BN.query(query)\n",
    "        except:\n",
    "            continue\n",
    "        if cardinality_predict is None:\n",
    "            continue\n",
    "        card_end_t = perf_counter()\n",
    "        latency_ms = (card_end_t - card_start_t) * 1000\n",
    "        if cardinality_predict == 0 and cardinality_true == 0:\n",
    "            q_error = 1.0\n",
    "        elif cardinality_predict == 0:\n",
    "            cardinality_predict = 1\n",
    "        elif cardinality_true == 0:\n",
    "            cardinality_true = 1\n",
    "\n",
    "        q_error = max(cardinality_predict / cardinality_true, cardinality_true / cardinality_predict)\n",
    "        print(f\"latency: {latency_ms} and error: {q_error}\")\n",
    "        latencies.append(latency_ms)\n",
    "        q_errors.append(q_error)\n",
    "    return latencies, q_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [50,90,95,99,100]:\n",
    "    print(np.percentile(q_errors, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
