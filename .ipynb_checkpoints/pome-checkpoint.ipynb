{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pomegranate\n",
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections\n",
    "import time\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Single_BN():\n",
    "    \"\"\"\n",
    "    Build a single Bayesian Network for a single table.\n",
    "    Initialize with an appropriate table_name.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, table_name):\n",
    "        self.table_name = table_name\n",
    "        self.n_in_bin = dict()\n",
    "        self.encoding = dict()\n",
    "        self.mapping = dict()\n",
    "        self.max_value = dict()\n",
    "        self.model = None\n",
    "        \n",
    "        \n",
    "    def build_discrete_table(self, table, n_mcv, n_bins, ignore_cols = []):\n",
    "        \"\"\"\n",
    "        Discretize the entire table use bining (This is using histogram method for continuous data)\n",
    "        ::Param:: table: original table\n",
    "                  n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                  n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "                  ignore_cols: drop the unnessary columns for example id attribute.\n",
    "        \"\"\"\n",
    "        table = table.copy()\n",
    "        for col in table.columns:\n",
    "            if col in ignore_cols:\n",
    "                table = table.drop(col, axis=1)\n",
    "            else:\n",
    "                table[col], self.n_in_bin[col], self.encoding[col], self.mapping[col] = tools.discretize_series(\n",
    "                    table[col],\n",
    "                    n_mcv=n_mcv,\n",
    "                    n_bins=n_bins\n",
    "                )\n",
    "                self.max_value[col] = table[col].max()\n",
    "        self.node_names = list(table.columns)\n",
    "        return table\n",
    "\n",
    "    def apply_encoding_to_value(self, value, col):\n",
    "        #return the encoded value given real value\n",
    "        if col not in self.encoding:\n",
    "            return value\n",
    "        elif value not in self.encoding[col]:\n",
    "            return value\n",
    "        return self.encoding[col][value]\n",
    "    \n",
    "    def apply_ndistinct_to_value(self, enc_value, value, col):\n",
    "        #return the number of distinct value in the bin\n",
    "        if col not in self.n_in_bin:\n",
    "            return 1\n",
    "        elif enc_value not in self.n_in_bin[col]:\n",
    "            return 1\n",
    "        elif type(self.n_in_bin[col][enc_value])==int:\n",
    "            return 1/self.n_in_bin[col][enc_value]\n",
    "        elif value not in self.n_in_bin[col][enc_value]:\n",
    "            return 1\n",
    "        else:\n",
    "            return self.n_in_bin[col][enc_value][value]\n",
    "    \n",
    "    def build_from_data(self, dataset, n_mcv=30, n_bins=60, ignore_cols=['id'], algorithm=\"greedy\", max_parents=-1, root=None, n_jobs=8):\n",
    "        \"\"\" Build the Pomegranate model from data, including structure learning and paramter learning\n",
    "            ::Param:: dataset: pandas.dataframe\n",
    "                      n_mcv: for categorical data we keep the top n most common values and bin the rest\n",
    "                      n_bins: number of bins for histogram, larger n_bins will provide more accuracy but less efficiency\n",
    "            for other parameters, pomegranate gives a detailed explaination:\n",
    "            https://pomegranate.readthedocs.io/en/latest/BayesianNetwork.html\n",
    "        \"\"\"\n",
    "        self.nrows = len(dataset)\n",
    "        self.algorithm = algorithm\n",
    "        self.max_parents = max_parents\n",
    "        self.n_mcv = n_mcv\n",
    "        self.n_bins = n_bins\n",
    "        self.root = root\n",
    "        \n",
    "        discrete_table = self.build_discrete_table(dataset, n_mcv, n_bins, ignore_cols)\n",
    "        print(f'building pomegranate.BayesianNetwork from data with {self.nrows} rows')\n",
    "        t = time.time()\n",
    "        self.model = pomegranate.BayesianNetwork.from_samples(discrete_table,\n",
    "                                                  algorithm=algorithm,\n",
    "                                                  state_names=self.node_names,\n",
    "                                                  max_parents=max_parents,\n",
    "                                                  n_jobs=8,\n",
    "                                                  root = self.root)\n",
    "        print(f'Took {time.time() - t} secs.')\n",
    "        \n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"bn{self.table_name}.{self.algorithm}-{self.max_parents}-{self.root}-{self.n_mcv}-{self.n_bins}\"\n",
    "    \n",
    "    def load(self, path, pgm_path=None):\n",
    "        with open(path, 'r') as myfile:\n",
    "            json_model = myfile.read()\n",
    "        self.model = BayesianNetwork.from_json(json_model)\n",
    "            \n",
    "    def save(self, path, pgm_path=None):\n",
    "        with open(path, 'w') as outfile:\n",
    "            outfile.write(self.model.to_json())\n",
    "            \n",
    "    \n",
    "    def loopy_belief_propagation(self, evidence, n_distinct):\n",
    "        p_estimates = 1\n",
    "        for i in range(len(evidence)):\n",
    "            val = evidence[i]\n",
    "            if val is not None:\n",
    "                evidence[i] = None\n",
    "                dist = self.model.predict_proba(evidence)\n",
    "                p = dist[i].parameters[0][val]*n_distinct[i]\n",
    "                p_estimates *= p\n",
    "        return p_estimates\n",
    "            \n",
    "    def infer_point_query(self, query, num_samples=1, return_prob=False):\n",
    "        \"\"\"Probability inference using learnt model. For example estimate P(X=x, Y=y, Z=z)\n",
    "           ::Param:: query: dictionary of the form {X:x, Y:y, Z:z}\n",
    "                     x,y,z can only be a single value\n",
    "                     num_samples: how many times to run inference. Since Loopy belief propagation is sometime\n",
    "                     an approaximation, we might to run it for multiple times and take the average.\n",
    "                     return_prob: if true, return P(X=x, Y=y, Z=z)\n",
    "                                  else return P(X=x, Y=y, Z=z)*nrows\n",
    "        \"\"\"\n",
    "        ncols = len(query)\n",
    "        nrows = self.nrows\n",
    "        \n",
    "        if num_samples == 1:\n",
    "            #Using topological order to infer probability\n",
    "            sampling_order = []\n",
    "            while len(sampling_order) < len(self.model.structure):\n",
    "                for i, deps in enumerate(self.model.structure):\n",
    "                    if i in sampling_order:\n",
    "                        continue  # already ordered\n",
    "                    if all(d in sampling_order for d in deps):\n",
    "                        sampling_order.append(i)\n",
    "                    \n",
    "        evidence = [None]*len(self.node_names)\n",
    "        n_distinct = [1]*len(self.node_names)\n",
    "        for attr in query:\n",
    "            ind = self.node_names.index(attr)\n",
    "            evidence[ind] = self.apply_encoding_to_value(query[attr], attr)\n",
    "            n_distinct[ind] = self.apply_ndistinct_to_value(evidence[ind], query[attr], attr)\n",
    "        \n",
    "        for i in num_samples:\n",
    "            \n",
    "                \n",
    "        \n",
    "        if return_prob:\n",
    "            return (p_estimates, nrows)\n",
    "        return int(p_estimates * nrows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table_csv(n = 20):\n",
    "    \"\"\"\n",
    "    Reads csv from path\n",
    "    n: every nth line = 1% of the lines\n",
    "    \"\"\"\n",
    "    filename = \"/Users/ziniuwu/Desktop/research/imdb/title.csv\"\n",
    "    df = pd.read_csv(filename, header=0, escapechar='\\\\', encoding='utf-8', quotechar='\"',\n",
    "                          sep=',', skiprows=lambda i: i % n != 0)\n",
    "    df.columns=['id', 'title', 'imdb_index', 'kind_id', 'production_year', 'imdb_id',\n",
    "                                                'phonetic_code', 'episode_of_id', 'season_nr', 'episode_nr',\n",
    "                                                'series_years', 'md5sum']\n",
    "    for name in ['episode_of_id', 'title', 'imdb_index', 'phonetic_code', 'season_nr',\n",
    "                                                  'imdb_id', 'episode_nr', 'series_years', 'md5sum']:\n",
    "        df = df.drop(name, axis=1)\n",
    "    df['random1'] = np.random.randint(10, size=len(df))\n",
    "    df['random2'] = np.random.randint(3, size=len(df))+10\n",
    "    df['random3'] = np.random.normal(3, 100, size=len(df))\n",
    "    return df.apply(pd.to_numeric, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziniuwu/anaconda3/envs/env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>kind_id</th>\n",
       "      <th>production_year</th>\n",
       "      <th>random1</th>\n",
       "      <th>random2</th>\n",
       "      <th>random3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122463</td>\n",
       "      <td>7</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>129.582521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33079</td>\n",
       "      <td>7</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>243.064620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111657</td>\n",
       "      <td>7</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-97.417777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51440</td>\n",
       "      <td>7</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>-42.620029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67012</td>\n",
       "      <td>7</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>58.652039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110274</td>\n",
       "      <td>7</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>66.282334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91401</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>124.914509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44624</td>\n",
       "      <td>7</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>-41.182882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>194183</td>\n",
       "      <td>2</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>-59.472201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41025</td>\n",
       "      <td>7</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>101.319601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128726</td>\n",
       "      <td>7</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>125.783119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>126494</td>\n",
       "      <td>7</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>-108.029661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>179243</td>\n",
       "      <td>7</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>156.883946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>160283</td>\n",
       "      <td>7</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>-7.608935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>172862</td>\n",
       "      <td>7</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>64.150444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18510</td>\n",
       "      <td>7</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>43.938950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>110047</td>\n",
       "      <td>7</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>160.353738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>63988</td>\n",
       "      <td>7</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>-66.679516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>78151</td>\n",
       "      <td>7</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>96.676493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>183809</td>\n",
       "      <td>7</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>40.771804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  kind_id  production_year  random1  random2     random3\n",
       "0   122463        7           2006.0        3       10  129.582521\n",
       "1    33079        7           2009.0        8       10  243.064620\n",
       "2   111657        7           2011.0        2       11  -97.417777\n",
       "3    51440        7           1999.0        3       12  -42.620029\n",
       "4    67012        7           2007.0        8       10   58.652039\n",
       "5   110274        7           1970.0        2       10   66.282334\n",
       "6    91401        7              NaN        2       10  124.914509\n",
       "7    44624        7           1990.0        9       11  -41.182882\n",
       "8   194183        2           2003.0        9       10  -59.472201\n",
       "9    41025        7           2012.0        4       11  101.319601\n",
       "10  128726        7           1999.0        2       10  125.783119\n",
       "11  126494        7           1979.0        3       12 -108.029661\n",
       "12  179243        7           2007.0        7       11  156.883946\n",
       "13  160283        7           2004.0        8       12   -7.608935\n",
       "14  172862        7           2011.0        3       10   64.150444\n",
       "15   18510        7           1962.0        3       10   43.938950\n",
       "16  110047        7           2009.0        7       12  160.353738\n",
       "17   63988        7           2010.0        5       12  -66.679516\n",
       "18   78151        7           2007.0        6       10   96.676493\n",
       "19  183809        7           1960.0        3       12   40.771804"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_table_csv(20)\n",
    "print(len(df))\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building pomegranate.BayesianNetwork from data with 126401 rows\n",
      "Took 2.62218976020813 secs.\n"
     ]
    }
   ],
   "source": [
    "BN = Single_BN('title')\n",
    "BN.build_from_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(evidence, BN):\n",
    "    pred = BN.model.predict_proba([None, None, None, None, None])\n",
    "    p = 1\n",
    "    for (col, v) in evidence:\n",
    "        i = BN.node_names.index(col)\n",
    "        print(pred[i].parameters[0][BN.encoding[col][v]])\n",
    "        p*=pred[i].parameters[0][BN.encoding[col][v]]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.query('production_year == 1999').query('random1 == 2').query('random2 == 10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "0.019390669377615584\n",
      "0.10040268668760531\n",
      "0.3339372315092444\n",
      "0.0006501341485049419\n"
     ]
    }
   ],
   "source": [
    "print(BN.infer_point_query({'production_year': 1999, 'random1':2, 'random2':10}))\n",
    "print(debug([('production_year', 1999), ('random1', 2), ('random2',10)], BN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = BN.build_discrete_table(BN.dataset, ignore_cols = ['id'])\n",
    "df['random1'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = BN.model.predict_proba([None, None, 5, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[2].parameters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['as','an','apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.index('as')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'as': 1, 'an': 2, 'apple':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(c)!=0:\n",
    "    c.pop(key)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
